<!DOCTYPE html>
<html lang="pl-pl">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>Ethics of Technology, AI, and Neuroethics 2024/2025 - Michał Wyrwa</title><meta name="Description" content="This is my cool site"><meta property="og:url" content="https://michalwyrwa.org/posts/teaching/ethics/">
  <meta property="og:site_name" content="Michał Wyrwa">
  <meta property="og:title" content="Ethics of Technology, AI, and Neuroethics 2024/2025">
  <meta property="og:description" content="This is my cool site">
  <meta property="og:locale" content="pl_pl">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-12-31T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-12-31T00:00:00+00:00">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Ethics of Technology, AI, and Neuroethics 2024/2025">
  <meta name="twitter:description" content="This is my cool site">
<meta name="application-name" content="My cool site">
<meta name="apple-mobile-web-app-title" content="My cool site"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://michalwyrwa.org/posts/teaching/ethics/" /><link rel="prev" href="https://michalwyrwa.org/posts/teaching/mixphi/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Ethics of Technology, AI, and Neuroethics 2024/2025",
        "inLanguage": "pl-pl",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/michalwyrwa.org\/posts\/teaching\/ethics\/"
        },"genre": "posts","wordcount":  1059 ,
        "url": "https:\/\/michalwyrwa.org\/posts\/teaching\/ethics\/","datePublished": "2024-12-31T00:00:00+00:00","dateModified": "2024-12-31T00:00:00+00:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "mw"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="fixed" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Michał Wyrwa">Michał Wyrwa</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/research/"><i class='fas fa-copy'></i> research </a><a class="menu-item" href="/categories/classes/"><i class='fas fa-user-graduate'></i> teaching </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Michał Wyrwa">Michał Wyrwa</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/research/" title=""><i class='fas fa-copy'></i>research</a><a class="menu-item" href="/categories/classes/" title=""><i class='fas fa-user-graduate'></i>teaching</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content always-active" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Ethics of Technology, AI, and Neuroethics 2024/2025</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>mw</a></span>&nbsp;<span class="post-category">included in <a href="/categories/classes/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Classes</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="313131-09-00">313131-09-00</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;1059 words&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;5 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#general-info">General info</a></li>
        <li><a href="#course-calendar">Course Calendar</a>
          <ul>
            <li><a href="#2702-lets-meet-introduction--course-organization">(27.02) Let&rsquo;s meet (introduction &amp; course organization)</a></li>
            <li><a href="#603-neuroscience--responsibility">(6.03) Neuroscience &amp; responsibility</a></li>
            <li><a href="#1303-neuroenhancements">(13.03) Neuroenhancements</a></li>
            <li><a href="#2003-ai-autonomy--responsibility">(20.03) AI Autonomy &amp; responsibility</a></li>
            <li><a href="#2703-algorithmic-bias--fairness-in-ai">(27.03) Algorithmic bias &amp; fairness in AI</a></li>
            <li><a href="#304-privacy-surveillance--neuro-rights">(3.04) Privacy, surveillance, &amp; neuro-rights</a></li>
            <li><a href="#1004-generative-ai">(10.04) Generative AI</a></li>
            <li><a href="#2404-technology--the-future-of-work">(24.04) Technology &amp; the future of work</a></li>
            <li><a href="#805-relationships-with-artificial-agents">(8.05) Relationships with artificial agents</a></li>
            <li><a href="#1505-technology--climate-change">(15.05) Technology &amp; climate change</a></li>
            <li><a href="#2205-drop-in-consultations-regarding-your-ethical-impact-assessment">(22.05) Drop-in consultations regarding your Ethical Impact Assessment</a></li>
            <li><a href="#2905-eia-presentations">(29.05) EIA presentations</a></li>
            <li><a href="#506-span-stylecolor-ad2a1astrongfinal-examstrongspan">(5.06) <span style="color: #AD2A1A;"><strong>Final exam</strong></span></a></li>
            <li><a href="#1206-makeup-exam-if-needed">(12.06) Makeup exam (if needed)</a></li>
          </ul>
        </li>
        <li><a href="#course-format--assessment">Course Format &amp; Assessment</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><h2 id="general-info">General info</h2>
<div class="details admonition info">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-info-circle fa-fw" aria-hidden="true"></i>Having psychological or other difficulties? (click)<i class="details-icon fas fa-angle-right fa-fw" aria-hidden="true"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content"><p>If you&rsquo;re feeling overwhelmed by your studies and facing challenges beyond your resources and abilities, you can reach out to the <a href="https://amu.edu.pl/studenci/studenci-z-niepelnosprawnosciami/Psychologiczny-konsultant-ds.-trudnosci-w-procesie-studiowania" target="_blank" rel="noopener noreffer ">psychological consultant for study-related difficulties <i class='fas fa-briefcase-medical'></i></a>.</p>
<p>If you&rsquo;re going through a difficult time or need support for any reason, don&rsquo;t hesitate or feel ashamed to seek<a href="https://amu.edu.pl/studenci/przewodnik_studenta/pomoc-psychologiczna" target="_blank" rel="noopener noreffer ">psychological help <i class='fas fa-briefcase-medical'></i></a>. Additionally, <a href="https://psychologia.amu.edu.pl/dla-studenta/wsparcie" target="_blank" rel="noopener noreffer ">our faculty members offer free psychological support in the form of phone consultation for students<i class='fas fa-briefcase-medical'></i></a>.</p>
<p><strong>If you&rsquo;re facing technological or health-related difficulties that prevent or significantly hinder your studies, please contact me so we can work out a plan for your participation.</strong>.</p>
</div>
        </div>
    </div>
<p>This elective course is dedicated to develop your ability to analyze and address ethical challenges related to neuroscience, AI, and broader technological advancements.</p>
<p>(The information on this page pertains to the Spring 2024/2025 edition).</p>
<p>Key details:</p>
<ul>
<li>We meet on Thursdays at 9:45AM.</li>
<li>Each session explores a different ethical challenge related to AI, neuroethics, and technology.</li>
<li>Office hours, i.e., <i class="fas fa-coffee"></i> time: Wednesdays 11&ndash;13 and Fridays 11:30&ndash;13:00 (Room 65AB). Email: michal.wyrwa [at] amu.edu.pl.</li>
<li>Discussions on morally sensitive topics require a safe environment&mdash;let&rsquo;s work together to create an inclusive and constructive space.</li>
<li>Prior experience with philosophy, neuroscience, or AI is not required (but always nice to have:)). The focus is on practical ethical reasoning, not technical expertise or history of philosophy.</li>
</ul>
<h2 id="course-calendar">Course Calendar</h2>
<h3 id="2702-lets-meet-introduction--course-organization">(27.02) Let&rsquo;s meet (introduction &amp; course organization)</h3>
<p>Foundations of neuroethics, AI ethics, and technology ethics&mdash;i.e., what is applied ethics? Overview of the course structure.</p>
<h3 id="603-neuroscience--responsibility">(6.03) Neuroscience &amp; responsibility</h3>
<p>The role of neuroscience and neuroprediction in criminal justice.
To do:</p>
<ul>
<li>Watch the two-part PBS documentary <em>Brains on Trial with Alan Alda</em> (<a href="https://www.youtube.com/watch?v=o0eSqIAmKxU" target="_blank" rel="noopener noreffer ">p. 1</a> and <a href="https://www.youtube.com/watch?v=_cBK_fgTZvk" target="_blank" rel="noopener noreffer ">p. 2</a>).</li>
<li>Find a recent real-world case where neuroevidence was used in court.</li>
<li>Review discussion questions &ndash; <a href="https://uam-my.sharepoint.com/:w:/g/personal/mw34272_amu_edu_pl/EdJPOks-NrBBsFdOjl9gZ9MBLrJ4Y3nuSnqyDywzP7xhXA?e=hrefOP" target="_blank" rel="noopener noreffer ">onedrive</a>.</li>
</ul>
<h3 id="1303-neuroenhancements">(13.03) Neuroenhancements</h3>
<p>Ethical and practical considerations of using neuroehancing substances and technologies.
To do:</p>
<ul>
<li>Find two real-life examples of neuroenhancement: one with a positive and one with a negative effect (according to you).</li>
<li>Review discussion questions &ndash; <a href="https://uam-my.sharepoint.com/:w:/g/personal/mw34272_amu_edu_pl/EcLCVJt7CRZEh8zVu0NcDd8B3TVB4u13T032yoSHUBG1Hg?e=5tkgow" target="_blank" rel="noopener noreffer ">onedrive</a>.</li>
</ul>
<h3 id="2003-ai-autonomy--responsibility">(20.03) AI Autonomy &amp; responsibility</h3>
<p>When is AI making a decision vs. just executing a process? Responsibility vs. accountability of AI, developers, policymakers, and users. Who should decide what AI can decide?
To do:</p>
<ul>
<li>Join one of three groups:
<ul>
<li>AI Companies&rsquo; Innocence – “Developers should not be liable for AI decisions. The technology is neutral.”</li>
<li>Governmental Regulations  – “Governments must take full responsibility for AI’s effects.”</li>
<li>User Responsibility – “The users of AI (companies, consumers) should be responsible for what AI does.”</li>
</ul>
</li>
<li>Prepare structured arguments on the debate points &ndash; <a href="https://uam-my.sharepoint.com/:w:/g/personal/mw34272_amu_edu_pl/Ec3MYJRqYRtCpw7G_7UTVIQBsIV-5wlgzJapefY-z3cduw?e=QGhWZl" target="_blank" rel="noopener noreffer ">onedrive</a> &ndash; and create a slide summarizing key claims and supporting data.</li>
</ul>
<h3 id="2703-algorithmic-bias--fairness-in-ai">(27.03) Algorithmic bias &amp; fairness in AI</h3>
<p>Bias in hiring, policing, facial recognition, and predictive analytics; ethical mitigation strategies&mdash;should we bias AI toward fairness?
To do:</p>
<ul>
<li>Read about Gender Shades &ndash; <a href="http://gendershades.org" target="_blank" rel="noopener noreffer ">www</a>.</li>
<li>Find another recent example of AI bias (excluding generative AI&mdash;covered later).</li>
<li>Bring a phone/laptop with access to the internet.</li>
<li>Review discussion questions &ndash; <a href="#" rel="">onedrive</a>.</li>
</ul>
<h3 id="304-privacy-surveillance--neuro-rights">(3.04) Privacy, surveillance, &amp; neuro-rights</h3>
<p>Privacy issues in AI; surveillance capitalism, technofeudalism; data privacy regulations.
To do:</p>
<ul>
<li>Review discussion questions &ndash; <a href="#" rel="">onedrive</a>.</li>
</ul>
<h3 id="1004-generative-ai">(10.04) Generative AI</h3>
<p>AI hallucinations, deepfakes, media manipulation, AI-generated propaganda, LLMs&rsquo; biases, who is accountable for AI-generated content? The ethics of creating vs. using generative AI.
To do:</p>
<ul>
<li>Bring a phone/laptop with access to the internet and a gAI tool of your choice.</li>
<li>Review discussion questions &ndash; <a href="#" rel="">onedrive</a>.</li>
</ul>
<h3 id="2404-technology--the-future-of-work">(24.04) Technology &amp; the future of work</h3>
<p>Will AI and other technologies replace human workers? Which professions are at risk? What benchmarks should we use to assess the impact? The ethics of algorithmic management and its consequences. Is technology a workforce equalizer or divider?
To do:</p>
<ul>
<li>Join one of three groups:
<ul>
<li>Tech Industry Advocates (AI will create more jobs than it destroys).</li>
<li>Labor Rights &amp; Unions (AI-driven automation is an existential threat to workers).</li>
<li>Regulators (The issue is not AI replacing jobs but how AI is regulated).</li>
</ul>
</li>
<li>Prepare structured arguments on the debate points &ndash; <a href="#" rel="">onedrive</a> &ndash; and create a slide summarizing key claims and supporting data.</li>
</ul>
<h3 id="805-relationships-with-artificial-agents">(8.05) Relationships with artificial agents</h3>
<p>Can people form meaningful relationships with AI? Is it ethical for AI to mimic human emotions? Should AI caregivers &amp; therapists replace human emotional support? Could AI ever “deserve” rights?
To do:</p>
<ul>
<li>Find one real-world example of controversial human-AI relationships (e.g., AI companions, therapists, or virtual influencers).</li>
<li>Review discussion questions &ndash; <a href="#" rel="">onedrive</a>.</li>
</ul>
<h3 id="1505-technology--climate-change">(15.05) Technology &amp; climate change</h3>
<p>The computational demands of computer technology vs. green, sustainable initiatives; real impact of technology on the environment vs. Silicon Valley optimism.
To do:</p>
<ul>
<li>Find one real-world example of AI’s carbon footprint or &ldquo;green AI/IT” initiatives and prepare a short (5-8 min.) presentation about it.</li>
</ul>
<h3 id="2205-drop-in-consultations-regarding-your-ethical-impact-assessment">(22.05) Drop-in consultations regarding your Ethical Impact Assessment</h3>
<h3 id="2905-eia-presentations">(29.05) EIA presentations</h3>
<h3 id="506-span-stylecolor-ad2a1astrongfinal-examstrongspan">(5.06) <span style="color: #AD2A1A;"><strong>Final exam</strong></span></h3>
<ul>
<li>List of questions will be given in advance.:)</li>
</ul>
<h3 id="1206-makeup-exam-if-needed">(12.06) Makeup exam (if needed)</h3>
<h2 id="course-format--assessment">Course Format &amp; Assessment</h2>
<p>The course emphasizes interactive learning, balancing discussions, case analyses, and project-based work.</p>
<p>Most sessions will comprise of discussions based on pre-assigned questions, ending with a short lecture contextualizing key ethical issues. Some sessions will feature pre-assigned group debates, where you will be asked to take a structured position on controversial topics. Other times, we will focus on case studies, exploring data, or investigating certain issues hands-on (e.g., algorithmic biases).</p>
<p>Assessment structure:</p>
<ol>
<li>Ethical Impact Assessment (13pt)
<ul>
<li>Critical evaluation of a specific technology or a trend (e.g., a generative AI tool, neurotechnology, neuroenhancements, a social media platform&rsquo;s recommendation algorithms, predictive healthcare tools, etc.).</li>
<li>The project follows a structured auditing methodology, which we will discuss later during the term.</li>
<li>There is no written report required, but you will present your findings near the end of the semester.</li>
</ul>
</li>
<li>Final Exam (23pt)
<ul>
<li>Closed questions + a case analysis on ethical challenges in technology and neuroethics.</li>
<li>Designed to assess your ability to apply ethical thinking and analyze real-world neuro- and technological dillemas rather than pure memorization. But then, to properly think and analyze one needs some knowledge, right?</li>
</ul>
</li>
<li>Being prepared for class (20%, 9pt)
<ul>
<li>Active participation in discussions, debates, and group work.</li>
<li>For most meetings, a list of discussion questions will be provided, and you are expected to prepare responses.</li>
</ul>
</li>
</ol>
<p>In total, you can get 45 pkt:</p>
<ul>
<li>from 93% – 5.0 (&gt;54pt)</li>
<li>from 85% to 92% – 4.5 (&gt;38pt)</li>
<li>from 76% to 84% – 4.0 (&gt;34pt)</li>
<li>from 68% to 75% – 3.5 (&gt;30pt)</li>
<li>from 60% to 67% – 3.0 (&gt;27pt)</li>
<li>less than 60% – 2.0</li>
</ul></div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 313131-09-00</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/posts/teaching/mixphi/" class="prev" rel="prev" title="Methods in experimental philosophy of mind 2024/2025 (lab)"><i class="fas fa-angle-left fa-fw" aria-hidden="true"></i>Methods in experimental philosophy of mind 2024/2025 (lab)</a></div>
</div>
</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.127.0">Hugo</a> | Theme - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.11"><i class="far fa-kiss-wink-heart fa-fw" aria-hidden="true"></i> LoveIt</a>
                </div><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2019 - 2025</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank">mw</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":50},"comment":{}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
