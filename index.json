[{"categories":["research"],"content":"Publications Wyrwa, M. (2025). A More Ordinary Ordinary View of the “What it is Like”-Talk. Philosophia, 1-26. https://doi.org/10.1007/s11406-025-00865-2 Wyrwa, M. (2025). Eksperymenty myślowe. Jak testujemy rzeczywistość? Wydawnictwo Nauk Społecznych i Humanistycznych Uniwersytetu im. Adama Mickiewicza w Poznaniu. https://www.researchgate.net/publication/393661086_Eksperymenty_myslowe_Jak_testujemy_rzeczywistosc Wyrwa, M. (2025). The bad and the good about the phenomenal stance. Journal of Theoretical and Philosophical Psychology. https://doi.org/10.1037/teo0000316 Wyrwa, M. (2022). Does the folk concept of phenomenal consciousness exist? Diametros 19 (71), 46–66. https://doi.org/10.33392/diam.1751 Ras, M., Wyrwa, M., Stachowiak, J., Buchwald, M., Nowik, A. M., \u0026 Kroliczak, G. (2022). Complex tools and motor-to-mechanical transformations. Scientific Reports, 12(1), 8041. https://doi.org/10.1038/s41598-022-12142-3. Wyrwa, F., Wyrwa, M. (2022). Twardy reset – edukacja po pandemii [w:]: B. Niemierko i M. K. Szmigel (red.), Diagnozowanie kształcenia w edukacji stacjonarnej i zdalnej (173–181), Kraków: Grupa Tomami. Wyrwa, F., Wyrwa, M. (2021). Edukacja w kryzysie? I co dalej? [w:] B. Niemierko i M. K. Szmigel (red.), Zdalna i bezpośrednia diagnostyka edukacyjna (31–39), Kraków: Grupa Tomami. Wyrwa, F., Wyrwa, M., Wilkus-Wyrwa A. (2020). Wyzwania nauczania zdalnego. Perspektywa nauczyciela i ucznia. [w:] B. Niemierko i M. K. Szmigel (red.), Rola społeczna diagnostyki edukacyjnej (363–381), Kraków: Grupa Tomami. Wyrwa, M. (2018). Własna a cudza świadomość. Próba wyjścia z naukowego labiryntu świadomości na przykładzie filozofii eksperymentalnej. [w:] G. Króliczak, K. Łastowski, Ł. Przybylski, P. Przybysz, M. Urbański (red.), Filozof w krainie umysłów. Profesorowi Andrzejowi Klawiterowi w darze, Poznań: Wydawnictwo Naukowe Wydziału Nauk Społecznych UAM, 35–53. Wyrwa, F., Wilkus-Wyrwa, A., Wyrwa, M. (2018). Całość w edukacji to coś więcej niż suma szczegółów. [w:] B. Niemierko, M. K. Szmigel (red.), Wspomaganie rozwoju kompetencji diagnostycznych nauczycieli. Kraków: Grupa Tomami, 65–75. Wyrwa, M. (2016). Świadomość w kontekstach klinicznych. Zaburzenia, diagnostyka, problemy. Studia z kognitywistyki i filozofii umysłu 9(8), 48–60. doi:10.14746/skfu.2015.9.1.04 ","date":"5055-09-15","objectID":"/research/:1:0","tags":null,"title":"Research","uri":"/research/"},{"categories":["research"],"content":"Non-academic publications \u0026 commentaries (2025). AI w pracy nauczyciela. Dyrektor szkoły, nr 3. https://www.wolterskluwer.com/pl-pl/news/ai-w-pracy-nauczyciela-emilia-lipiec-kuzanska (2025). Brakuje strategii w zakresie podstaw programowych i wdrażania gSI w szkołach. Czas działać. Portal Samorządowy. https://www.portalsamorzadowy.pl/edukacja/brakuje-strategii-w-zakresie-podstaw-programowych-i-wdrazania-gsi-w-szkolach-czas-dzialac,597037.html (2022). Strategia Oświatowa Gminy Tarnowo Podgórne na lata 2022-2026 (2020). Wyzwania nauczania zdalnego. Wspólnota. Pismo samorządu terytorialnego 17(1309), 54-57. ","date":"5055-09-15","objectID":"/research/:2:0","tags":null,"title":"Research","uri":"/research/"},{"categories":["classes"],"content":"General info The course aims to develop participants’ ability to apply empirical methods to philosophical questions. We will explore how experimental findings shape philosophical debates within the broader cognitive science framework. Since the focus will be on understanding, designing, conducting, and analyzing empirical inquiries inspired by philosophy rather than delving into philosophical nuances, students are encouraged to familiarize themselves with the suggested theoretical literature. Each class will consist of a discussion on a key paper reading, a student presentation on follow-up studies, and research exercises. In mid-to-late November, we will also have a refresher on basic statistics, so ensure you have appropriate software installed (I’ll be using RStudio or Jamovi but you can work with whatever you are comfortable with). Please feel free to use generative AI to help enhance your understanding of papers, concepts, or methods, but don’t blindly trust its results. You may also use AI to improve the flow of your written work, but do not outsource the creation itself—this is one of the most crucial parts of what makes you you: your unique thought processes and perspectives. If you have questions about the course, feel free to drop me an email at michal.wyrwa [at] amu.edu.pl. I’m also available on Fridays from 11:30 to 12:30 in Room 65AB. And here are the PDFs: www. ","date":"1011-09-00","objectID":"/posts/teaching/mixphi/:1:0","tags":null,"title":"Methods in experimental philosophy of mind 2025/2026 (lab)","uri":"/posts/teaching/mixphi/"},{"categories":["classes"],"content":"Course calendar (Only compulsory readings are listed below. Ones for presentations are in the ‘Read-up literature’ section.) Introduction, formalities + about experimental philosophy (XPhi) (10.10) Sytsma, J., \u0026 Livengood, J. (2015). The New Experimental Philosophy. In The Theory and Practice of Experimental Philosophy (pp. 3–19). Broadview Press. Exploring the conceptual scheme of folk psychology + General introduction to scientific methodology (17.10) Weisman, K., Dweck, C. S., \u0026 Markman, E. M. (2017). Rethinking people’s conceptions of mental life. Proceedings of the National Academy of Sciences, 114(43), 11374–11379. (For a refresher on scientific inquiry and methodology) Morling, B. (2018). Research Methods in Psychology: Evaluating a World of Information (part 1, i.e., Introduction to Scientific Reasoning, 5-84) Why think phenomenal consciousness exists? + Formulating research problems and planning research (7.11) Sytsma, J., \u0026 Machery, E. (2010). Two conceptions of subjective experience. Philosophical Studies, 151(2), 299–327. Why think phenomenal consciousness exists? p. 2 (textual data) + Other XPhi questionnaire studies + Designing experimental tools (14.11) Sytsma, J., \u0026 Fischer, E. (2023). ‘Experience’, ordinary and philosophical: A corpus study. Synthese, 201(6), 210. Catch-up on statistics + Other XPhi studies with textual data (21.11) Stats class, practical session focusing on getting you on board with basic inferential statistics (correlations, differences, anova). And your short recaps of XPhi linguistic studies XPhi condition: worries and prospects + Analyzing data p. 1 (28.11) Bach, T. (2023). Limitations and Criticism of Experimental Philosophy. In A. M. Bauer \u0026 S. Kornmesser (Eds.), The Compact Compendium of Experimental Philosophy (pp. 101–130). De Gruyter. Exploring lived experiences (naturalizing phenomenology) + Analyzing data p. 2 (5.12) Petitmengin, C. (2006). Describing one’s subjective experience in the second person: An interview method for the science of consciousness. Phenomenology and the Cognitive Sciences, 5(3–4), 229–269. Petitmengin, C., Van Beek, M., Bitbol, M., Nissou, J.-M., \u0026 Roepstorff, A. (2019). Studying the experience of meditation through Micro-phenomenology. Current Opinion in Psychology, 28, 54–59. Test! (12.12) A detailed list of topics for the test will be provided in November Project meetings (individual/groups, general research idea) (19.12) Project meetings (individual/groups, experimental design and analysis plan) (9.01) Project meetings (individual/groups, progress report) (15.01/16.01) Reports deadline and project presentations! (23.01) ","date":"1011-09-00","objectID":"/posts/teaching/mixphi/:2:0","tags":null,"title":"Methods in experimental philosophy of mind 2025/2026 (lab)","uri":"/posts/teaching/mixphi/"},{"categories":["classes"],"content":"Grading You can collect up to 60 points: Exam (easier if you do presentation during class meetings, see below) (1/3 of total points) Assignments during classes (exercises, overall participation) (1/3 of total points) Final group project (1/3 of total points) Grading scale: 5.0: \u003e54pt 4.5: \u003e48 to 54pt 4.0: \u003e42 to 48pt 3.5: \u003e36 to 42pt 3.0: \u003e30 to 36pt 2.0: 0 to 30pt ","date":"1011-09-00","objectID":"/posts/teaching/mixphi/:3:0","tags":null,"title":"Methods in experimental philosophy of mind 2025/2026 (lab)","uri":"/posts/teaching/mixphi/"},{"categories":["classes"],"content":"Final project The final project involves designing, conducting, and analyzing a small XPhi study, with a written report (7 000-10 000 characters, following APA7) to present the results. Projects should be done individually or in groups of 2. The topic, methods, and analysis plan need to be approved during the compulsory project meetings. You can either fill a gap in the XPhi literature, do a cross-culture replication of an existing study, or propose a new design for a yet unexplored philosophical issue. Project meetings are compulsory, and the grade for the project will only be given after the vivas. The viva gives you an opportunity to defend your project and clarify any ambiguities that may have arisen from reading your report. Projects will be assessed based on their philosophical relevance, the validity of operationalization and experimental design, the rigor of results analysis and interpretation, and the overall quality of the manuscript. (Vivas will take place in a class setting, with a short presentation of your results to the other groups.) ","date":"1011-09-00","objectID":"/posts/teaching/mixphi/:3:1","tags":null,"title":"Methods in experimental philosophy of mind 2025/2026 (lab)","uri":"/posts/teaching/mixphi/"},{"categories":["classes"],"content":"Read-up literature for presentations The papers listed below are those you can choose from to make a short presentation (7-10 minutes explaining the research question, experimental design, and results). For each specified class meeting, there is time for up to three presentations. You may also cover a study that was omitted in an earlier class. Each presentation will reduce the number of exam questions by 1/3. Why think phenomenal consciousness exists? (questionnaires, p. 2) (7.11) ★ Sytsma, J., \u0026 Ozdemir, E. (2019). No Problem: Evidence that the Concept of Phenomenal Consciousness is Not Widespread. Journal of Consciousness Studies, 26(9–10), 241–256. ★ Díaz, R. (2021). Do people think consciousness poses a hard problem? Empirical evidence on the meta-problem of consciousness. Journal of Consciousness Studies, 28(2–4), 55–75. ★ Gregory, D., Hendrickx, M., \u0026 Turner, C. (2022). Who knows what Mary knew? An experimental study. Philosophical Psychology, 35(4), 522–545. Why think phenomenal consciousness exists? p. 2 (textual data) + Other XPhi questionnaire studies + Designing experimental tools (14.11) ★ Díaz, R. (2022). Emotions and the body. Testing the subtraction argument. Philosophical Psychology, 35(1), 47–65. ★ Nadelhoffer, T., Shepard, J., Crone, D. L., Everett, J. A. C., Earp, B. D., \u0026 Levy, N. (2020). Does encouraging a belief in determinism increase cheating? Reconsidering the value of believing in free will. Cognition, 203, 104342. ★ Salomons, T. V., Harrison, R., Hansen, N., Stazicker, J., Sorensen, A. G., Thomas, P., \u0026 Borg, E. (2022). Is Pain “All in your Mind”? Examining the General Public’s Views of Pain. Review of Philosophy and Psychology, 13(3), 683–698. ★ Cova, F., Gaillard, M., \u0026 Kammerer, F. (2020). Is the phenomenological overflow argument really supported by subjective reports? Mind and Language, May 2019, 1–29. Catch-up on statistics + Other XPhi studies with textual data (21.11) ★ Hansen, N., Porter, J. D., \u0026 Francis, K. (2019). A Corpus Study of “know”: On the Verification of Philosophers’ Frequency Claims about Language. Episteme, 1–27. ★ Reuter, K. (2024). Normativity and Concepts of Bodily Sensations, Studia Philosophica, 83, 55–73. ★ Loureiro, F., Garcia-Marques, T., \u0026 Wegener, D. T. (2024). More than meets the gut: A prototype analysis of the lay conceptions of intuition and analysis. Cognition and Emotion, 38(8), 1229–1245. ★ Wright, J. C., Sedlock, T., West, J., Saulpaugh, K., \u0026 Hopkins, M. (2016). Located in the thin of it: Young children’s use of thin moral concepts. Journal of Moral Education, 45(3), 308–323. XPhi condition: worries and prospects + Analyzing data p. 1 (28.11) ★ Cova, F., Strickland, B., Abatista, A., Allard, A., Andow, J., Attie, M., Beebe, J., Berniūnas, R., Boudesseul, … Zhou, X. (2021). Estimating the Reproducibility of Experimental Philosophy. Review of Philosophy and Psychology, 12, 9–44. ★ Landes, E., \u0026 Reuter, K. (2025). Conceptual Revision in Action. Review of Philosophy and Psychology. ★ Peters, U., \u0026 Lemeire, O. (2023). Hasty generalizations are pervasive in experimental philosophy: A systematic analysis. Philosophy of Science, 1-21. ★ Maćkiewicz, B., Kuś, K., \u0026 Hensel, W. M. (2023). The influence of philosophical training on the evaluation of philosophical cases: a controlled longitudinal study. Synthese, 202(4), 113. Exploring lived experiences (naturalizing phenomenology) + Analyzing data p. 2 (5.12) ★ Allen, K., Quinlan, P., Andow, J., \u0026 Fischer, E. (2021). What is it like to be colour‐blind? A case study in experimental philosophy of experience. Mind \u0026 Language, mila.12370. ★ Blundell, Emma. K., Grover, Laura. E., Stott, J., \u0026 Schrag, A. (2023). The experience of Anxiety for people with Parkinson’s disease. Npj Parkinson’s Disease, 9(1), 75. ★ Moskalewicz, M., Kordel, P., Kokociński, M., Wiertlewska-Bielarz, J., \u0026 Makowski, P. (2023). The rhythm of chemotherapy and the felt experience of time: a front-loaded phenomenological retrospective cohort study. Scienti","date":"1011-09-00","objectID":"/posts/teaching/mixphi/:4:0","tags":null,"title":"Methods in experimental philosophy of mind 2025/2026 (lab)","uri":"/posts/teaching/mixphi/"},{"categories":["classes"],"content":"Przedmiot obligatoryjny dla studentów I roku psychologii i kognitywistyki. Wszystkie informacje o przedmiocie znajdują się na Moodle’u. ","date":"1011-09-00","objectID":"/posts/teaching/ti/:0:0","tags":null,"title":"Technologia informacyjna 2025/2026","uri":"/posts/teaching/ti/"},{"categories":["classes"],"content":"Informacje ogólne Informacje na tej stronie dotyczą ćwiczeń, nie wykładu (kliknij) Informacje na tej stronie dotyczą ćwiczeń z WdF, uzupełniających wykłady dra Szymona Chlebowskiego WdF realizowane jest na pierwszym semestrze licencjackich studiów z kognitywistyki na UAM (30h wykładów, 15h ćwiczeń). Masz trudności technologiczne, psychologiczne i/lub inne? (kliknij) Jeśli doświadczasz kryzysu emocjonalnego i niepokoju z racji na sytuację pandemiczną, Wydział Psychologii i Kognitywistyki oferuje bezpłatne wsparcie i konsultacje psychologiczne . Jeśli czujesz, że studiowanie Cię przerasta, że napotykasz problemy ponad swoje siły i umiejętności, możesz zwrócić się do psychologicznego konsultanta do spraw trudności w studiowaniu . Jeśli przechodzisz przez gorszy okres lub potrzebujesz wsparcia z innego powodu, nie bój i nie wstydź się zasięgnąć pomocy psychologicznej . Jeśli masz trudności technologiczne lub zdrowotne, uniemożliwiające lub znacznie utrudniające realizowanie przedmiotu, proszę skontaktuj się ze mną celem wypracowania planu Twojego uczestnictwa w zajęciach. Dyżur we wtorki 11-14 i piątki 11:30-12:30 w bud. AB, p. 65. W inne dni jestem niedostępny w sprawach dydaktycznych (mogę odpisać/być, ale nic pewnego), Kontakt pod michal.wyrwa [at] amu.edu.pl. Każda grupa zajęcia ma raz na dwa tygodnie! W pierwszym cyklu zajęć gr. 1 i 3, w drugim gr. 2 i 4, następnie na zmianę. Teksty do przeczytania są dostępne tutaj. ","date":"1011-09-00","objectID":"/posts/teaching/wdf/:1:0","tags":null,"title":"Wstęp do filozofii 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdf/"},{"categories":["classes"],"content":"Zajęcia ","date":"1011-09-00","objectID":"/posts/teaching/wdf/:2:0","tags":null,"title":"Wstęp do filozofii 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdf/"},{"categories":["classes"],"content":"1. Jak filozofować? (13.10/20.10) Williamson, T. (2019). O co chodzi w filozofii? Od zdziwienia do myślenia, Wydawnictwo Naukowe PWN (fragmenty). ","date":"1011-09-00","objectID":"/posts/teaching/wdf/:2:1","tags":null,"title":"Wstęp do filozofii 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdf/"},{"categories":["classes"],"content":"2. Skąd wiemy, że wiemy? (27.10/3.11) Descartes, R., Medytacje o filozofii pierwszej, medytacja 1 i 2. Gettier, E. L. (1963). Is justified true belief knowledge? Analysis, 23(6), 121–123 (tłum. J. Hartman i J. Rabus). ","date":"1011-09-00","objectID":"/posts/teaching/wdf/:2:2","tags":null,"title":"Wstęp do filozofii 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdf/"},{"categories":["classes"],"content":"3. Co sprawia, że coś jest umysłem? (17.11/24.11) Ryle, G. (1970). Czym jest umysł?, Wydawnictwo Naukowe PWN, s. 41–60 (r. 1). Nagel, T. (1993). Co to wszystko znaczy? Bardzo krótkie wprowadzenie do filozofii, Wydawnictwo Spacja, s. 27–35 (r. 4) ","date":"1011-09-00","objectID":"/posts/teaching/wdf/:2:3","tags":null,"title":"Wstęp do filozofii 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdf/"},{"categories":["classes"],"content":"4. Co sprawia, że coś jest nauką? (1.12/8.12) Warburton, N. (1999). Filozofia od podstaw, Aletheia, r. 5. Such, J. (1997). Filozofia nauki, Wydawnictwo Naukowe UAM (fragmenty). ","date":"1011-09-00","objectID":"/posts/teaching/wdf/:2:4","tags":null,"title":"Wstęp do filozofii 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdf/"},{"categories":["classes"],"content":"5. Prawda (15.12/12.01) Tarski, A., ‘Prawda i dowód’, Scientific American 220, 1969, fragmenty. ","date":"1011-09-00","objectID":"/posts/teaching/wdf/:2:5","tags":null,"title":"Wstęp do filozofii 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdf/"},{"categories":["classes"],"content":"6. 😈 Kolokwium 😈 (19.01 – wszystkie grupy) ","date":"1011-09-00","objectID":"/posts/teaching/wdf/:2:6","tags":null,"title":"Wstęp do filozofii 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdf/"},{"categories":["classes"],"content":"7. Kolokwium poprawkowe (26.01 – wszyscy potrzebujący) ","date":"1011-09-00","objectID":"/posts/teaching/wdf/:2:7","tags":null,"title":"Wstęp do filozofii 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdf/"},{"categories":["classes"],"content":"Polityka oceniania i (nie)obecności Na spotkaniach trzymajcie się swoich grup USOSowych. Nieobecności Jednorazowe nieobecności nie stanowią problemu, ale częstsze już tak: w trosce o jakość Waszej partycypacji w zajęciach i tego, co możecie z nich wynieść, zaliczenie przedmiotu może być w takim przypadku bardziej kłopotliwe. 2 i 3 nieobecność skutkuje koniecznością odrobienia zajęć na dyżurze. Więcej niż 3 nieobecności oznaczają niezaliczenie zajęć. Maksymalnie można zdobyć 100 punktów, z czego: Kolokwium – do 80 pkt Wejściówki – do 20 pkt Skala ocen przedstawia się następująco: 50-59 pkt dostateczny 60-69 pkt dostateczny+ 70-79 pkt dobry 80-89 pkt dobry+ 90-100 pkt bardzo dobry Jeśli pod koniec semestru, po kolokwium, będzie Wam brakować punktów do zaliczenia, to zrobimy kolokwium poprawkowe. Na takowym trzeba będzie uzyskać co najmniej 61% by ćwiczenia zaliczyć pozytywnie. ","date":"1011-09-00","objectID":"/posts/teaching/wdf/:3:0","tags":null,"title":"Wstęp do filozofii 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdf/"},{"categories":["classes"],"content":"Informacje ogólne Informacje na tej stronie dotyczą ćwiczeń, nie wykładu (kliknij) Informacje na tej stronie dotyczą ćwiczeń z WdK uzupełniających wykłady dr Ł. Przybylskiego. WdK realizowane jest na pierwszym semestrze licencjackich studiów z kognitywistyki na UAM (30h wykładów, 30h ćwiczeń). Masz trudności technologiczne, psychologiczne i/lub inne? (kliknij) Jeśli doświadczasz kryzysu emocjonalnego i niepokoju, Wydział Psychologii i Kognitywistyki oferuje bezpłatne wsparcie i konsultacje psychologiczne . Jeśli czujesz, że studiowanie Cię przerasta, że napotykasz problemy ponad swoje siły i umiejętności, możesz zwrócić się do psychologicznego konsultanta do spraw trudności w studiowaniu . Jeśli przechodzisz przez gorszy okres lub potrzebujesz wsparcia z innego powodu, nie bój i nie wstydź się zasięgnąć pomocy psychologicznej . Jeśli masz trudności technologiczne lub zdrowotne, uniemożliwiające lub znacznie utrudniające realizowanie przedmiotu, proszę skontaktuj się ze mną celem wypracowania planu Twojego uczestnictwa w zajęciach. Kognitywistyka to nauka o umyśle, tego też dotyczą zajęcia: umysłów, które bywają ludzkie i nieludzkie, sztuczne i naturalne, świadome i nieświadome, które percypują, są emocjonalne, ucieleśnione i predykcyjne. Szczegóły co do oceniania i (nie)obecności znajdziecie na końcu strony. Dyżur we wtorki 11-14 i piątki 11:30-12:30 w bud. AB, p. 65. W inne dni jestem niedostępny w sprawach dydaktycznych (mogę odpisać/być, ale nic pewnego), Kontakt pod michal.wyrwa [at] amu.edu.pl. Na każde spotkanie przewidziany jest obligatoryjny materiał do analizy (do przerobienia ze zrozumieniem przed zajęciami. Zrozumienie oznacza przeanalizowanie tekstu kilka razy, wyłapanie kluczowych myśli, a nie przejechanie oczami po literkach). Znajomość materiału będzie na zajęciach sprawdzana i oceniana. Praktycznie wszystkie materiały są po polsku, a jeśli anglojęzyczne sprawiają wyzwanie, to możecie użyć tłumaczenia maszynowego. Na niektóre zajęcia będziecie przygotowywać i przedstawiać prezentacje, poszerzając zagadnienia poruszane w materiałach obligatoryjnych. Podział na zespoły przygotowujące prezentacje nastąpi w pierwszych tygodniach zajęć. Konieczne jest uzyskanie akceptacji gotowego pliku z prezentacją i planu wystąpienia na dyżurze przed ćwiczeniami. Proszę nie zostawiajcie pracy nad prezentacją na ostatnią chwilę. Rozmawiać możemy przez Teams, maila lub na żywo. Co dwa spotkania będziecie proszeni o przesyłanie swoich przemyśleń na jeden z dwóch przerobionych tematów. Przemyślenia powinny dotyczyć zagadnień poruszanych na spotkaniu, obecnych w materiałach obligatoryjnych lub dodatkowych: co Was zainteresowało; z czym nie zgadzacie (polemika), z czym zgadzacie, jak odnieśliście zdobytą wiedzę do swojego życia, który z przerabianych wątków mocniej zgłębiliście w wolnym czasie, et cetera. Sami decydujecie o czym dokładnie piszecie: to okazja do refleksji nad swoimi przekonaniami i emocjami nt. poruszanych zagadnień. Jedna dawka przemyśleń = 150-300 słów. Do ich przesyłania udostępniony będzie formularz. Za przemyślenia są punkty, ale nie za ich treść, a za to czy mają wymaganą objętość, są samodzielne i dotyczą któregoś z tematu zajęć. I tak, łatwo takie coś wygenerować w całości. Ale po co, naprawdę wolisz aby to SI wymyśliła za Ciebie, co myślisz? Przemyślenia nie mają dobrej i złej odpowiedzi, nie są straszne, są po prostu Twoimi myślami. Pokaż sobie, że potrafisz układać zdania w akapit. Napisz sam_. DEADLINE to zawsze piątek 11:30 w tygodniu, w którym przerabiamy “drugi” z tematów. Szczegółowa punktacja na dole strony. Potrzebne materiały: www. ","date":"1011-09-00","objectID":"/posts/teaching/wdk/:1:0","tags":null,"title":"Wstęp do kognitywistyki 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdk/"},{"categories":["classes"],"content":"Zajęcia ","date":"1011-09-00","objectID":"/posts/teaching/wdk/:2:0","tags":null,"title":"Wstęp do kognitywistyki 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdk/"},{"categories":["classes"],"content":"1. O kognitywistyce (+ uwagi organizacyjne) (9.10) Do doczytania po zajęciach: Edward Nęcka i in. (2020). Psychologia poznawcza. Wydawnictwo Naukowe PWN, s. 33–35. ","date":"1011-09-00","objectID":"/posts/teaching/wdk/:2:1","tags":null,"title":"Wstęp do kognitywistyki 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdk/"},{"categories":["classes"],"content":"2. Teoretyczne podstawy nauki o umyśle (16.10) Steven Pinker (2022). Jak działa umysł? (r. 1 Standardowe wyposażenie). Zysk i S-ka. ","date":"1011-09-00","objectID":"/posts/teaching/wdk/:2:2","tags":null,"title":"Wstęp do kognitywistyki 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdk/"},{"categories":["classes"],"content":"3. Sztuczny umysł (23.10) Alan Turing (1995/1950). Maszyna licząca a inteligencja. W: B. Chwedeńczuk (red.), Fragmenty filozofii analitycznej, tom II, Filozofia umysłu. SPACJA, s. 271–300. Moret i in. (2025). When AI Seems Conscious: Here’s What to Know. https://whenaiseemsconscious.org. Ethan Mollick (2025). *Against “Brain Damage”. AI can help, or hurt, our thinking. https://www.oneusefulthing.org/p/against-brain-damage. [PREZENTACJA] John Searle (1995/1980). Umysły, mózgi i programy. W: B. Chwedeńczuk (red.), Fragmenty filozofii analitycznej, tom II, Filozofia umysłu. SPACJA, s. 301–324. ","date":"1011-09-00","objectID":"/posts/teaching/wdk/:2:3","tags":null,"title":"Wstęp do kognitywistyki 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdk/"},{"categories":["classes"],"content":"4. Umysł percypujący (6.11) James Kalat (2020). Biologiczne podstawy psychologii (r. 5.1 i 5.2). Wydawnictwo Naukowe PWN. [PREZENTACJA] * James Kalat (2020). Biologiczne podstawy psychologii (r. 5.3). Wydawnictwo Naukowe PWN. ","date":"1011-09-00","objectID":"/posts/teaching/wdk/:2:4","tags":null,"title":"Wstęp do kognitywistyki 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdk/"},{"categories":["classes"],"content":"5. Ewolucja umysłów (13.11) Peter Godfrey-Smith (2018). Inne umysły. Ośmiornice i prapoczątki świadomości (r. 2). Copernicus Center Press, s. 29–60. Peter Godfrey-Smith (2023). Metazoa. Od szklanych gąbek i morskich smoków do ukrytej krainy umysłu (r. 2). Copernicus Center Press. [PREZENTACJA] Daniel Dennett (1997). Natura umysłów (fragment r. 2 Intencjonalność: systemy intencjonalne, r. 4 Historia intencjonalności). Wydawnictwo CIS, s. 31-39, 99–138. ","date":"1011-09-00","objectID":"/posts/teaching/wdk/:2:5","tags":null,"title":"Wstęp do kognitywistyki 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdk/"},{"categories":["classes"],"content":"6. Umysł świadomy (20.11) David Chalmers (2010). Świadomy umysł (r. 1 Dwa pojęcia umysłu). Wydawnictwo Naukowe PWN, s. 29–73. Christof Koch (2018). Czym jest świadomosć? Świat Nauki 7, s. 57–60. [PREZENTACJA] Monti, M. M., Vanhaudenhuyse, A., Coleman, M. R., Boly, M., Pickard, J. D., Tshibanda, L., … \u0026 Laureys, S. (2010). Willful modulation of brain activity in disorders of consciousness. New England Journal of Medicine, 362(7), 579-589. ","date":"1011-09-00","objectID":"/posts/teaching/wdk/:2:6","tags":null,"title":"Wstęp do kognitywistyki 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdk/"},{"categories":["classes"],"content":"7. 😈 Kolokwium 1 😈 (27.11) ","date":"1011-09-00","objectID":"/posts/teaching/wdk/:2:7","tags":null,"title":"Wstęp do kognitywistyki 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdk/"},{"categories":["classes"],"content":"8. Czytanie umysłów (4.12) Arkadiusz Gut (2016). Badania kognitywne i rozwojowe nad czytaniem umysłu (mindreading). W: J. Bremer (red.), Przewodnik po kognitywistyce. Wydawnictwo WAM, fragmenty. Daniel Dennett (1997). Natura umysłów (fragment r. 2 Intencjonalność: systemy intencjonalne). Wydawnictwo CIS, s. 39-70. [PREZENTACJA] Simon Baron-Cohen (2009/1997). Rozwój zdolności czytania innych umysłów: cztery etapy. W: A. Klawiter (red.), Formy aktywności umysłu, t. 2. Wydawnictwo Naukowe PWN, s. 145–171. ","date":"1011-09-00","objectID":"/posts/teaching/wdk/:2:8","tags":null,"title":"Wstęp do kognitywistyki 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdk/"},{"categories":["classes"],"content":"9. Umysły pozaludzkie (11.12) Franz de Waal (2016). Bystre zwierzę. Czy jesteśmy dość mądrzy, aby zrozumieć mądrość zwierząt? (r. 3 Fale kognitywne) Copernicus Center Press. [PREZENTACJA] Maciej Trojan (2013). Na tropie zwierzęcego umysłu (r. 3 Komunikacja społeczna i posługiwanie się językiem). Wydawnictwo Naukowe Scholar, s. 27-76. ","date":"1011-09-00","objectID":"/posts/teaching/wdk/:2:9","tags":null,"title":"Wstęp do kognitywistyki 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdk/"},{"categories":["classes"],"content":"10. Umysł emocjonalny (18.12) James Kalat (2020). Biologiczne podstawy psychologii (r. 11.1 i 11.2). Wydawnictwo Naukowe PWN. [PREZENTACJA] Joseph LeDoux (2017). Lęk. Neuronauka na tropie źródeł lęku i strachu. Copernicus Center Press, fragmenty. ","date":"1011-09-00","objectID":"/posts/teaching/wdk/:2:10","tags":null,"title":"Wstęp do kognitywistyki 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdk/"},{"categories":["classes"],"content":"11. Umysł ucieleśniony (8.01) Michał Wierzchoń, Marta Łukowska (2016). Ucieleśnione poznanie. W: J. Bremer (red.), Przewodnik po kognitywistyce. Wydawnictwo WAM, fragmenty (s. 605-608). Aleksandra Szymków (2018). Umysł uwolniony. O poznaniu zakorzenionym w ciele i świecie społecznym. Wydawnictwo Naukowe Scholar, s. 201-214 (r. Poznanie dystrybuowane). ","date":"1011-09-00","objectID":"/posts/teaching/wdk/:2:11","tags":null,"title":"Wstęp do kognitywistyki 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdk/"},{"categories":["classes"],"content":"12. Właściciel umysłu (15.01) Thomas Metzinger (2018/2009). Tunel Ego. Naukowe badanie umysłu i mit świadomego ja. Wydawnictwo Uniwersytetu Łódzkiego, r. 3 (Z ciała do umysłu. Obraz ciała, eksterioryzacja i jaźń wirtualna). [PREZENTACJA] James Kalat (2020). Biologiczne podstawy psychologii. Wydawnictwo Naukowe PWN, s. 290-292. [PREZENTACJA] Chun Siong Soon, Marcel Brass, Hans-Jochen Heinze, John-Dylan Haynes (2008). Unconscious determinants of free decision in the human brain. Nature Neuroscience 11(5), s. 543-545. ","date":"1011-09-00","objectID":"/posts/teaching/wdk/:2:12","tags":null,"title":"Wstęp do kognitywistyki 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdk/"},{"categories":["classes"],"content":"13. 😈 Kolokwium 2 😈 (22.01) ","date":"1011-09-00","objectID":"/posts/teaching/wdk/:2:13","tags":null,"title":"Wstęp do kognitywistyki 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdk/"},{"categories":["classes"],"content":"15. Kolokwium poprawkowe (29.01) Jeśli zajdzie taka potrzeba. ","date":"1011-09-00","objectID":"/posts/teaching/wdk/:2:14","tags":null,"title":"Wstęp do kognitywistyki 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdk/"},{"categories":["classes"],"content":"Polityka oceniania i (nie)obecności Na spotkaniach trzymajcie się swoich grup USOSowych. Nieobecności Jednorazowe nieobecności nie stanowią problemu, ale częstsze już tak: w trosce o jakość Waszej partycypacji w zajęciach i tego, co możecie z nich wynieść, zaliczenie przedmiotu może być w takim przypadku bardziej kłopotliwe. 3 i 4 nieobecność skutkuje koniecznością odrobienia zajęć na dyżurze. Więcej niż 4 nieobecności oznaczają niezaliczenie zajęć. Maksymalnie można zdobyć 100 punktów, z czego: Prezentacja – do 10 pkt Kolokwia – do 70 pkt (pierwsze na 25 pkt, drugie na 45 pkt) Pozostałe (przemyślenia i wejściówki) – do 20 pkt (5pkt i 15pkt) Na kolokwiach obowiazują treści z tekstów obligatoryjnych oraz treści obecne na zajęciach. Ocena końcowa wystawiana jest zgodnie z poniższą skalą: bdb: 91-100pkt db+: 81-90pkt db: 71-80pkt dst+: 61-70pkt dst: 51-60pkt ndst: nie więcej niż 50pkt Jeśli pod koniec semestru, po teście końcowym, będzie Wam brakować punktów do zaliczenia, to zrobimy zaliczenie poprawkowe. Na takowym obowiązuje materiał z całego semestru, z którego trzeba będzie uzyskać co najmniej 61% by ćwiczenia zaliczyć pozytywnie. ","date":"1011-09-00","objectID":"/posts/teaching/wdk/:3:0","tags":null,"title":"Wstęp do kognitywistyki 2025/2026 (ćwiczenia)","uri":"/posts/teaching/wdk/"},{"categories":["classes"],"content":"General info Having psychological or other difficulties? (click) If you’re feeling overwhelmed by your studies and facing challenges beyond your resources and abilities, you can reach out to the psychological consultant for study-related difficulties . If you’re going through a difficult time or need support for any reason, don’t hesitate or feel ashamed to seek psychological help . Additionally, our faculty members offer free psychological support in the form of phone consultation for students. If you’re facing technological or health-related difficulties that prevent or significantly hinder your studies, please contact me so we can work out a plan for your participation.. This elective course is dedicated to develop your ability to analyze and address ethical challenges related to neuroscience, AI, and broader technological advancements. (The information on this page pertains to the Spring 2024/2025 edition). Key details: We meet on Thursdays at 9:45AM. Each session explores a different ethical challenge related to AI, neuroethics, and technology. Office hours, i.e., time: Tuesdays 11–13 and Fridays 11:30–13:00 (Room 65AB). Email: michal.wyrwa [at] amu.edu.pl. Discussions on morally sensitive topics require a safe environment—let’s work together to create an inclusive and constructive space. Prior experience with philosophy, neuroscience, or AI is not required (but always nice to have:)). The focus is on practical ethical reasoning, not technical expertise or history of philosophy. Readings and handouts are available here. Note that readings are available for each session. They are listed in the discussion questions. Some of them are marked with a ‘★’—these are particularly important for your future self preparing for the exam. By the end of March, you will receive a detailed list of exam questions and key topics. The readings are there for your reference: ★-marked ones are required for the exam, but you don’t have to read them for our meetings. Of course, you’re welcome to, but for discussion purposes, it’s just as valuable to research the topic online and engage with different perspectives. ","date":"313131-09-00","objectID":"/posts/teaching/ethics/:1:0","tags":null,"title":"Ethics of Technology, AI, and Neuroethics 2024/2025","uri":"/posts/teaching/ethics/"},{"categories":["classes"],"content":"Course Calendar ","date":"313131-09-00","objectID":"/posts/teaching/ethics/:2:0","tags":null,"title":"Ethics of Technology, AI, and Neuroethics 2024/2025","uri":"/posts/teaching/ethics/"},{"categories":["classes"],"content":"(27.02) Let’s meet (introduction \u0026 course organization) Foundations of neuroethics, AI ethics, and technology ethics—i.e., what is applied ethics? Overview of the course structure. ","date":"313131-09-00","objectID":"/posts/teaching/ethics/:2:1","tags":null,"title":"Ethics of Technology, AI, and Neuroethics 2024/2025","uri":"/posts/teaching/ethics/"},{"categories":["classes"],"content":"(6.03) Neuroscience \u0026 responsibility The role of neuroscience and neuroprediction in criminal justice. To do: Watch the two-part PBS documentary Brains on Trial with Alan Alda (p. 1 and p. 2). Find a recent real-world case where neuroevidence was used in court. Review discussion questions – onedrive. ","date":"313131-09-00","objectID":"/posts/teaching/ethics/:2:2","tags":null,"title":"Ethics of Technology, AI, and Neuroethics 2024/2025","uri":"/posts/teaching/ethics/"},{"categories":["classes"],"content":"(13.03) Neuroenhancements Ethical and practical considerations of using neuroehancing substances and technologies. To do: Find two real-life examples of neuroenhancement: one with a positive and one with a negative effect (according to you). Review discussion questions – onedrive. ","date":"313131-09-00","objectID":"/posts/teaching/ethics/:2:3","tags":null,"title":"Ethics of Technology, AI, and Neuroethics 2024/2025","uri":"/posts/teaching/ethics/"},{"categories":["classes"],"content":"(20.03) AI Autonomy \u0026 responsibility When is AI making a decision vs. just executing a process? Responsibility vs. accountability of AI, developers, policymakers, and users. Who should decide what AI can decide? To do: Join one of three groups (sign up here): AI Companies’ Innocence – “Developers should not be liable for AI decisions. The technology is neutral.” Governmental Regulations – “Governments must take full responsibility for AI’s effects.” User Responsibility – “The users of AI (companies, consumers) should be responsible for what AI does.” Prepare structured arguments on the debate points – onedrive – and create a slide summarizing key claims and supporting data. ","date":"313131-09-00","objectID":"/posts/teaching/ethics/:2:4","tags":null,"title":"Ethics of Technology, AI, and Neuroethics 2024/2025","uri":"/posts/teaching/ethics/"},{"categories":["classes"],"content":"(27.03) Algorithmic bias \u0026 fairness in AI Bias in hiring, policing, facial recognition, and predictive analytics; ethical mitigation strategies—should we bias AI toward fairness? To do: Read about Gender Shades – www. Find another recent example of AI bias (excluding generative AI—covered later). Review discussion questions – onedrive. ","date":"313131-09-00","objectID":"/posts/teaching/ethics/:2:5","tags":null,"title":"Ethics of Technology, AI, and Neuroethics 2024/2025","uri":"/posts/teaching/ethics/"},{"categories":["classes"],"content":"(3.04) Privacy, surveillance, \u0026 neuro-rights Privacy issues in AI; surveillance capitalism, technofeudalism; data privacy regulations. To do: Review discussion questions – onedrive. ","date":"313131-09-00","objectID":"/posts/teaching/ethics/:2:6","tags":null,"title":"Ethics of Technology, AI, and Neuroethics 2024/2025","uri":"/posts/teaching/ethics/"},{"categories":["classes"],"content":"(24.04) Generative AI AI hallucinations, deepfakes, media manipulation, AI-generated propaganda, LLMs’ biases, who is accountable for AI-generated content? The ethics of creating vs. using generative AI. To do: Review discussion questions – onedrive. ","date":"313131-09-00","objectID":"/posts/teaching/ethics/:2:7","tags":null,"title":"Ethics of Technology, AI, and Neuroethics 2024/2025","uri":"/posts/teaching/ethics/"},{"categories":["classes"],"content":"(8.05) Technology \u0026 the future of work Will AI and other technologies replace human workers? Which professions are at risk? What benchmarks should we use to assess the impact? The ethics of algorithmic management and its consequences. Is technology a workforce equalizer or divider? To do: You will join one of two groups and prepare a structured response to one of the questions. Is AI really replacing workers, or is this just another tech bubble? Is technology making the workplace fairer or more exploitative? Consider creating a slide summarizing key claims and supporting data. More details are available here – onedrive. ","date":"313131-09-00","objectID":"/posts/teaching/ethics/:2:8","tags":null,"title":"Ethics of Technology, AI, and Neuroethics 2024/2025","uri":"/posts/teaching/ethics/"},{"categories":["classes"],"content":"(15.05) Relationships with artificial agents Can people form meaningful relationships with AI? Is it ethical for AI to mimic human emotions? Should AI caregivers \u0026 therapists replace human emotional support? Could AI ever “deserve” rights? To do: Find one real-world example of controversial human-AI relationships (e.g., AI companions, therapists, or virtual influencers). Review discussion questions – onedrive. ","date":"313131-09-00","objectID":"/posts/teaching/ethics/:2:9","tags":null,"title":"Ethics of Technology, AI, and Neuroethics 2024/2025","uri":"/posts/teaching/ethics/"},{"categories":["classes"],"content":"(22.05) Technology \u0026 climate change The computational demands of computer technology vs. green, sustainable initiatives; real impact of technology on the environment vs. Silicon Valley optimism. To do: Review discussion questions – onedrive. ","date":"313131-09-00","objectID":"/posts/teaching/ethics/:2:10","tags":null,"title":"Ethics of Technology, AI, and Neuroethics 2024/2025","uri":"/posts/teaching/ethics/"},{"categories":["classes"],"content":"(23.05) Drop-in consultations regarding your Ethical Impact Assessment ","date":"313131-09-00","objectID":"/posts/teaching/ethics/:2:11","tags":null,"title":"Ethics of Technology, AI, and Neuroethics 2024/2025","uri":"/posts/teaching/ethics/"},{"categories":["classes"],"content":"(29.05) EIA presentations ","date":"313131-09-00","objectID":"/posts/teaching/ethics/:2:12","tags":null,"title":"Ethics of Technology, AI, and Neuroethics 2024/2025","uri":"/posts/teaching/ethics/"},{"categories":["classes"],"content":"(5.06) Final exam !!Exam scope!! ","date":"313131-09-00","objectID":"/posts/teaching/ethics/:2:13","tags":null,"title":"Ethics of Technology, AI, and Neuroethics 2024/2025","uri":"/posts/teaching/ethics/"},{"categories":["classes"],"content":"(12.06) Makeup exam (if needed) ","date":"313131-09-00","objectID":"/posts/teaching/ethics/:2:14","tags":null,"title":"Ethics of Technology, AI, and Neuroethics 2024/2025","uri":"/posts/teaching/ethics/"},{"categories":["classes"],"content":"Course Format \u0026 Assessment The course emphasizes interactive learning, balancing discussions, case analyses, and project-based work. Most sessions will comprise of discussions based on pre-assigned questions, ending with a short lecture contextualizing key ethical issues. Some sessions will feature pre-assigned group debates, where you will be asked to take a structured position on controversial topics. Other times, we will focus on case studies, exploring data, or investigating certain issues hands-on (e.g., algorithmic biases). Assessment structure: Ethical Impact Assessment (13pt) Critical evaluation of a specific technology or a trend (e.g., a generative AI tool, neurotechnology, neuroenhancements, a social media platform’s recommendation algorithms, predictive healthcare tools, etc.). The project follows a structured auditing methodology, which we will discuss later during the term. There is no written report required, but you will present your findings near the end of the semester. This template includes detailed explanations on what to include and how to perform your assessment: template Final Exam (23pt) Closed questions + a case analysis on ethical challenges in technology and neuroethics. Designed to assess your ability to apply ethical thinking and analyze real-world neuro- and technological dillemas rather than pure memorization. But then, to properly think and analyze one needs some knowledge, right? Being prepared for class (20%, 9pt) Active participation in discussions, debates, and group work. For most meetings, a list of discussion questions will be provided, and you are expected to prepare responses. In total, you can get 45 pkt: from 93% – 5.0 (≥41pt) from 85% to 92% – 4.5 (≥38pt) from 76% to 84% – 4.0 (≥34pt) from 68% to 75% – 3.5 (≥30pt) from 60% to 67% – 3.0 (≥27pt) less than 60% – 2.0 If you don’t want to complete an Ethical Impact Assessment, you can instead prepare a ~20-minute presentation segment for one of the following sessions (individually or in pairs). The presentation should cover the current state of the debate on a given ethical topic and the latest relevant data. Privacy, surveillance, \u0026 neuro-rights Generative AI Relationships with artificial agents Technology \u0026 climate change ","date":"313131-09-00","objectID":"/posts/teaching/ethics/:3:0","tags":null,"title":"Ethics of Technology, AI, and Neuroethics 2024/2025","uri":"/posts/teaching/ethics/"},{"categories":["classes"],"content":"Informacje ogólne Informacje na tej stronie dotyczą ćwiczeń, nie wykładu (kliknij) Informacje na tej stronie dotyczą ćwiczeń z FilUm, uzupełniających zajęcia z prof. UAM dr hab. P. Przybyszem. FilUm to zajęcia na czwartym semestrze licencjackich studiów z kognitywistyki na UAM (30h wykładów, 30h ćwiczeń). Masz trudności technologiczne, psychologiczne i/lub inne? (kliknij) Jeśli doświadczasz kryzysu emocjonalnego i niepokoju z racji na sytuację pandemiczną, Wydział Psychologii i Kognitywistyki oferuje bezpłatne wsparcie i konsultacje psychologiczne . Jeśli czujesz, że studiowanie Cię przerasta, że napotykasz problemy ponad swoje siły i umiejętności, możesz zwrócić się do psychologicznego konsultanta do spraw trudności w studiowaniu . Jeśli przechodzisz przez gorszy okres lub potrzebujesz wsparcia z innego powodu, nie bój i nie wstydź się zasięgnąć pomocy psychologicznej . Jeśli masz trudności technologiczne lub zdrowotne, uniemożliwiające lub znacznie utrudniające realizowanie przedmiotu, proszę skontaktuj się ze mną abyśmy mogli wypracować plan Twojego uczestnictwa w zajęciach. na spotkaniach wykładowych zapoznajecie się z rdzeniem filozofii umysł, na ćw też, ale zajmiemy się również forpocztą filozofii umysłu, widzimy się w poniedziałki o 11:30 (s. 304D), wspólna , czyli dyżur: czwartki 9-11. Mail: michal.wyrwa [at] amu.edu.pl, zapisy na konsultacje: youcanbook.me (przyda się w drugiej połowie semestru), link do materiałów do zdobycia na zajęciach, na przedmiocie będziecie czytać filozofię i o filozofii, dlatego polecam: Concepción, D. W. (2004), Reading Philosophy with Background Knowledge and Metacognition, ,,Teaching Philosophy’’ 27(4), s. 358-368 (czyli Appendix: How to Read Philosophy) ","date":"313131-09-00","objectID":"/posts/teaching/fu/:1:0","tags":null,"title":"Filozofia umysłu 2023/2024","uri":"/posts/teaching/fu/"},{"categories":["classes"],"content":"Spotkania ","date":"313131-09-00","objectID":"/posts/teaching/fu/:2:0","tags":null,"title":"Filozofia umysłu 2023/2024","uri":"/posts/teaching/fu/"},{"categories":["classes"],"content":"(26.02) Spotkanie zapoznawcze ","date":"313131-09-00","objectID":"/posts/teaching/fu/:2:1","tags":null,"title":"Filozofia umysłu 2023/2024","uri":"/posts/teaching/fu/"},{"categories":["classes"],"content":"(4.03) Filozofia w kognitywistyce Núñez, R., Allen, M., Gao, R., Rigoli, C. M., Relaford-Doyle, J., \u0026 Semenuks, A. (2019). What happened to cognitive science? Nature Human Behaviour, 3(8), 782-791 ","date":"313131-09-00","objectID":"/posts/teaching/fu/:2:2","tags":null,"title":"Filozofia umysłu 2023/2024","uri":"/posts/teaching/fu/"},{"categories":["classes"],"content":"(11.03) Superinteligencja Bostrom, N. (2016/2014). Superinteligencja. Scenariusze, strategie, zagrożenia, Helion, r. 3 ","date":"313131-09-00","objectID":"/posts/teaching/fu/:2:3","tags":null,"title":"Filozofia umysłu 2023/2024","uri":"/posts/teaching/fu/"},{"categories":["classes"],"content":"(18.03) Czy można intersubiektywnie badać świadomość? A. Lutz, E. Thompson (2017/2003), ,,Neurofenomenologia: integrowanie doświadczenia subiektywnego i dynamiki neuronalnej w neuronauce świadomości’’, w Główne problemy współczesnej fenomenologii, red. J. Migański, M. Pokropski, Wydawnictwo Uniwersytetu Warszawskiego, s. 458–486 ","date":"313131-09-00","objectID":"/posts/teaching/fu/:2:4","tags":null,"title":"Filozofia umysłu 2023/2024","uri":"/posts/teaching/fu/"},{"categories":["classes"],"content":"(25.03) Eksperymentalna filozofia umysłu Díaz, R. (2021). Do people think consciousness poses a hard problem? Empirical evidence on the meta-problem of consciousness, Journal of Consciousness Studies , 28(2–4), s. 55–76 ","date":"313131-09-00","objectID":"/posts/teaching/fu/:2:5","tags":null,"title":"Filozofia umysłu 2023/2024","uri":"/posts/teaching/fu/"},{"categories":["classes"],"content":"(15.04) Minimal/plant cognition Baluška, F., \u0026 Levin, M. (2016). On having no head: Cognition throughout biological systems. Frontiers in Psychology, 7(JUN), 1–19. ","date":"313131-09-00","objectID":"/posts/teaching/fu/:2:6","tags":null,"title":"Filozofia umysłu 2023/2024","uri":"/posts/teaching/fu/"},{"categories":["classes"],"content":"(22.04) Relacje psychofizyczne - panpsychizm Strawson, G. (2018/2017). Fizykalistyczny panpsychizm, Roczniki Filozoficzne, 66(1), 181–205 ","date":"313131-09-00","objectID":"/posts/teaching/fu/:2:7","tags":null,"title":"Filozofia umysłu 2023/2024","uri":"/posts/teaching/fu/"},{"categories":["classes"],"content":"(29.04) Jaźń i tożsamość osobowa Bremer, J. (2012), ,,Jaźń i tożsamość osobowa’’, w Przewodnik po filozofii umysłu, red. M Miłkowski, R. Poczobut, Wydawnictwo WAM, s. 427-462 Chalmers, D. J. (2014). Uploading: A philosophical analysis. w Intelligence Unbound: Future of Uploaded and Machine Minds, 102-118. ","date":"313131-09-00","objectID":"/posts/teaching/fu/:2:8","tags":null,"title":"Filozofia umysłu 2023/2024","uri":"/posts/teaching/fu/"},{"categories":["classes"],"content":"(6.05) Projekt w sali Więcej szczegółów na zajęciach ","date":"313131-09-00","objectID":"/posts/teaching/fu/:2:9","tags":null,"title":"Filozofia umysłu 2023/2024","uri":"/posts/teaching/fu/"},{"categories":["classes"],"content":"(13.05, 14.05) Konsultacje indywidualne #1 DEADLINE akceptacji tematu i literatury - 17.05 ","date":"313131-09-00","objectID":"/posts/teaching/fu/:2:10","tags":null,"title":"Filozofia umysłu 2023/2024","uri":"/posts/teaching/fu/"},{"categories":["classes"],"content":"(20.05, 21.05) Konsultacje indywidualne #2 DEADLINE oddania prac zaliczeniowych 24.05 ","date":"313131-09-00","objectID":"/posts/teaching/fu/:2:11","tags":null,"title":"Filozofia umysłu 2023/2024","uri":"/posts/teaching/fu/"},{"categories":["classes"],"content":"(27.05, 28.05) Obrona prac zaliczeniowych Okazja na wybronienie swojej pracy pisemnej i polepszenie oceny. ","date":"313131-09-00","objectID":"/posts/teaching/fu/:2:12","tags":null,"title":"Filozofia umysłu 2023/2024","uri":"/posts/teaching/fu/"},{"categories":["classes"],"content":"(27.05) Ewentualna poprawka/zwycięska kawa Kolokwium poprawkowe ","date":"313131-09-00","objectID":"/posts/teaching/fu/:2:13","tags":null,"title":"Filozofia umysłu 2023/2024","uri":"/posts/teaching/fu/"},{"categories":["classes"],"content":"Polityka oceniania i (nie)obecności Nieobecności Jednorazowe nieobecności nie stanowią problemu, ale częstsze już tak: w trosce o jakość Waszej partycypacji w zajęciach i tego, co możecie z nich wynieść, zaliczenie przedmiotu może być w takim przypadku bardziej kłopotliwe. 3 i 4 nieobecność skutkuje koniecznością odrobienia zajęć. Więcej niż 4 nieobecności oznaczają niezaliczenie zajęć. Zdobyć można 70 punktów: do 30 pkt na spotkaniach (w tym za projekt w sali) do 40 pkt za esej Ocena końcowa wystawiana jest zgodnie z poniższą skalą: co najmniej 60 pkt: bdb 54-59 pkt: db+ 48-53 pkt: db 42-47 pkt: dst+ 36-41 pkt: dst mniej niż 36 pkt: nzal Jeśli pod koniec semestru, będzie Wam brakować punktów do zaliczenia, to zrobimy kolokwium poprawkowe. Na takowym obowiązuje materiał z całego semestru, z którego trzeba uzyskać co najmniej 61% by ćwiczenia zaliczyć pozytywnie. ","date":"313131-09-00","objectID":"/posts/teaching/fu/:3:0","tags":null,"title":"Filozofia umysłu 2023/2024","uri":"/posts/teaching/fu/"},{"categories":["classes"],"content":"Esej Praca zaliczeniowa musi dotyczyć wybranego przez jej autora/autorkę problemu filozoficznego. Problem powinien nawiązywać do tematyki poruszanej na ćwiczeniach i/lub wykładzie. Esej powinien mieć charakter argumentacyjny. ","date":"313131-09-00","objectID":"/posts/teaching/fu/:4:0","tags":null,"title":"Filozofia umysłu 2023/2024","uri":"/posts/teaching/fu/"},{"categories":["classes"],"content":"Etapy pracy nad esejem Pierwsza tura konsultacji: wybór tematu i literatury. Temat i wybrane teksty muszą zostać zaakceptowane do 17 maja!! Propozycję tematu i tekstów proszę podesłać na mail: możemy też zdzwonić się na Teamsie, jak Wam wygodniej :). Druga tura konsultacji (indywidualne krótkie rozmowy o argumentacji i innych bolączkach pisania) DEADLINE oddania eseju: 24.05 ‘Obrona’ eseju, czyli rozmowa o pracy, jest to rozmowa obowiązkowa. ","date":"313131-09-00","objectID":"/posts/teaching/fu/:4:1","tags":null,"title":"Filozofia umysłu 2023/2024","uri":"/posts/teaching/fu/"},{"categories":["classes"],"content":"Wymogi formalne Szczegółowe omówienie pisania eseju (wraz z przykładami i szczegółową punktacją) jest dostępne w materiałach dla studentów. Spełnienie poniższych jest konieczne, by esej był sprawdzany: objętość: 2000-3250 słów, język pracy: pl / eng abstrakt, ok. 250 słów (wliczany w limit słów)*, bibliografia, odnośniki i formatowanie w stylu APA**, praca wysłana w pdfie o nazwie ``nazwisko_imie_filUm_2023_2024.pdf’’, skorzystanie z przynajmniej trzech tekstów naukowych spoza obligatoryjnych lektur na ćwiczenia i wykład***. Oczywiście esej ma zdawać sprawę z WASZEGO myślenia, nie wygenerowanych pomysłów na argumenty. * Dla tekstu filozoficznego abstrakt powinien odpowiadać na pytania: czego dotyczy tekst (tło pracy)? Jaka jest teza pracy? Jak teza zostaje uargumentowana? ** Aktualne, anglojęzyczne, materiały można znaleźć na oficjalnej stronie apastyle.apa.org. Opublikowano też półoficjalną wersję polską. Word o365 ma templatkę do artykułu w stylu APA!! *** Przyjmuję następujące kryterium: tekst naukowy to tekst recenzowany przez innych naukowców. Najczęściej takie teksty są publikowane w czasopiśmach naukowych lub w wydawnictwach naukowych. Dobre punkty startowe poszukiwań: PhilPapers i Google Scholar. ","date":"313131-09-00","objectID":"/posts/teaching/fu/:4:2","tags":null,"title":"Filozofia umysłu 2023/2024","uri":"/posts/teaching/fu/"},{"categories":["classes"],"content":"Jak pisać? Rippon, S. (2008), A Brief Guide to Writing the Philosophy Paper, Harvard College Writing Center [PDF] 13 wskazówek na temat pisania Stevena Pinkera [PDF] Taylor, D., The Literature Review: A Few Tips On Conducting It, Uniwersytet w Toronto, [PDF] ","date":"313131-09-00","objectID":"/posts/teaching/fu/:4:3","tags":null,"title":"Filozofia umysłu 2023/2024","uri":"/posts/teaching/fu/"},{"categories":["blog"],"content":"tl;dr I uploaded my Pandoc workflow to GitHub, feel free to use it Having an unobtrusive workflow is important. There are things about writing that just take too much time when done by hand. Text formatting and file converting are two that I especially hate. People expect different things. Some want .docx, others .tex or .pdfs, all complying with a set of strict formatting rules. Often enough a faithful conversion of .odt to .docx means spending hours on fiddling with margins, fonts, and other details. And do not get me started on ‘We want .tex files!’. I think that writing itself should be separated from such mundane worries. While I absolutely love a good-looking document, if you have something to write, then write it and do not worry about the looks. Write in Notepad, in .txt, in Word, in TeX, whatever. Worry about the final format and aesthetics later. Pandoc is a command-line universal document converter. Html, .epub, LaTeX, Markdown, .rtf, .doc, anything can be converted to anything. You just need to set some rules. I uploaded my Pandoc scripts on GitHub. I use Scrivener for most of my writing, but I believe in writing in plain text. So i export my Scrivener projects to Markdown. I set up the script to accept .md file and a .bib file. As most of the times I need a .pdf with a .docx or .tex reference, Pandoc converts .md accordingly. Example, a draft-looking PDF: A little bit better looking PDF: The .md file just needs to have a title field in the YAML metadata. The script is dead simple on purpose, so that anyone with 101 in BASH can understand it and tweak it. It uses free fonts: (Lato and STIX), as well as apa and spbasic csl/bst files. If you do not use .bib for your bibliography, Mendeley and other apps have export to bibtex option. In Mendeley you can make it so that every time you add a record to your library, a .bib file is automatically updated. Symlink that file to Pandoc script’s directory and you are good to go. I know there are more academic-oriented Pandoc templates (pandoc-scholar), Pandoc automation tools (pandocomatic), and even Scrivener Ruby script for compiling for pandocomatic (scrivomatic). While these are great, they are too robust for my needs. Cheers ","date":"8088-09-00","objectID":"/posts/2019-06-08-pandocscripts/:0:1","tags":null,"title":"Writing workflow: Pandoc scripts","uri":"/posts/2019-06-08-pandocscripts/"},{"categories":["blog"],"content":"[This is a post from my old website. Outdated packages and libraries. Viewer discretion is advised ;-)] W tym artykule stworzymy prostą aplikację na Android wyświetlającą aktualną pozycję Międzynarodowej Stacji Kosmicznej, wykorzystującą ViewModel, LiveData oraz bibliotekę Retrofit. Przy okazji wyjaśnimy jak działają dodane w zeszłym roku komponenty architektury Androida. Aplikacja wyglądać będzie tak: {: .align-center} ","date":"292929-09-00","objectID":"/posts/2018-04-29-viewmodel/:0:0","tags":null,"title":"[OLD] ISS, Architecture: ViewModel, LiveData, Retrofit","uri":"/posts/2018-04-29-viewmodel/"},{"categories":["blog"],"content":"Komponenty architektury Androida Architecture Components to biblioteki dla Androida, zaprezentowane przez Google na I/O ‘17. Mają one ułatwić proces projektowania architektury aplikacji. Dotąd zespół Androida nie rekomendował żadnego konkretnego wzorca architektury. A tych popularnych trochę jest, by wymienić same model-view-*. Dodatkowe komponenty i rekomendowany przepływ danych można zobrazować tak: {: .align-center} Warstwa UI oddzielona jest od tej częsci kodu, która jest odpowiedzialna za zdobywanie i przygotowywanie danych przez ViewModel. Obiekty tej klasy nie są niszczone wskutek zmian konfiguracyjnych aplikacji (np. zmiany orientacji ekranu), są lifecycle-aware, więc nie ma już potrzeby pakowania multum danych w onSaveInstanceState(). ViewModel przetrwa, jeśli w Activity, w której był przywołany, zostanie użyte onDestroy(), o ile tylko nie będzie to się wiązało z wywołaniem metody finish() (więcej tutaj). Sam ViewModel również nie ma być odpowiedzialny za operacje na bazie danych albo zewnętrznym API, dostaje takie gotowe dane z Repository. Sama klasa Repository nie wchodzi w skład bibliotek Architecture Components. Obiekty należące do tej klasy mają pośredniczyć w wymianie danych pomiędzy źródłem danych (API/SQLite/itd.) a ViewModelem. Biblioteka Room to warstwa abstrakcji nad SQLite, ułatwiająca (= mniej kodu) dostęp i manipulację danymi z bazy danych. Od strony RESTfulowych usług, pobierania danych spoza naszej aplikacji przy pomocy jakiegoś API, Android nie dostarcza gotowej biblioteki. W dokumentacji natomiast korzysta z Retrofit, stąd gwiazdka na diagramie :). Pozostaje kwestia LiveData. Jest to data holder, który może być obserwowany. Innymi słowy, jeśli nasze dane zostaną przekazane przez ViewModel do warstwy UI jako LiveData, to obserwowanie stanu danych w LiveData wystarczy, by przy zmianie w danych zmianie też uległa wyświetlana dla użytkownika treść na ekranie. ","date":"292929-09-00","objectID":"/posts/2018-04-29-viewmodel/:1:0","tags":null,"title":"[OLD] ISS, Architecture: ViewModel, LiveData, Retrofit","uri":"/posts/2018-04-29-viewmodel/"},{"categories":["blog"],"content":"Aplikacja WhereIsSpaceStation W tym wpisie zajmiemy się “prawą stroną” diagramy. Nie będziemy niczego zapisywać w bazie danych, wykorzystamy LiveData, ViewModel, Repository i Retrofit by wyświetlić na ekranie aktualną pozycję ISS. Po naciśnięciu przycisku informacja na ekranie będzie aktualizowana. W przyszłości dodamy też bazę danych. Skorzystamy z: Android Studio (na dzień pisania wpisu jest to wersja 3.1.1) OpenNotify API Retrofit Biblioteki Architecture Components ","date":"292929-09-00","objectID":"/posts/2018-04-29-viewmodel/:2:0","tags":null,"title":"[OLD] ISS, Architecture: ViewModel, LiveData, Retrofit","uri":"/posts/2018-04-29-viewmodel/"},{"categories":["blog"],"content":"Ustawienia projektu Tworzymy nowy projekt w Android Studio: {: .align-center} {: .align-center} Resztę ustawień pozostawiamy domyślne. Kreator powinien nam stworzyć nowy projekt, z jedną Activity (wedle templatki EmptyActivity). Nasza aplikacja będzie korzystać z połączenia z internetem, więc w AndroidManifest.xml musimy dodać: \u003cuses-permission android:name=\"android.permission.INTERNET\"/\u003e Architecture Components na dzień dzisiejszy trzeba ręcznie dodać do projektu. W build.gradle projektu sprawdzamy, czy wśród repozytoriów znajduje się google(): repositories { google() jcenter() } A w build.gradle na poziomie modułu aplikacji dodajemy potrzebne biblioteki. Aktualne wersje bibliotek znaleźć można tutaj: dependencies { implementation fileTree(dir: 'libs', include: ['*.jar']) implementation 'com.android.support:appcompat-v7:27.1.0' implementation 'com.android.support.constraint:constraint-layout:1.1.0' testImplementation 'junit:junit:4.12' androidTestImplementation 'com.android.support.test:runner:1.0.1' androidTestImplementation 'com.android.support.test.espresso:espresso-core:3.0.1' // Javax annotation implementation 'org.glassfish:javax.annotation:10.0-b28' // Retrofit implementation 'com.squareup.retrofit2:retrofit:2.4.0' implementation 'com.squareup.retrofit2:converter-gson:2.4.0' // ViewModel and LiveData implementation \"android.arch.lifecycle:extensions:1.1.1\" // alternatively, just ViewModel implementation \"android.arch.lifecycle:viewmodel:1.1.1\" // alternatively, just LiveData implementation \"android.arch.lifecycle:livedata:1.1.1\" annotationProcessor \"android.arch.lifecycle:compiler:1.1.1\" // Room (use 1.1.0-beta3 for latest beta) implementation \"android.arch.persistence.room:runtime:1.0.0\" annotationProcessor \"android.arch.persistence.room:compiler:1.0.0\" // Paging implementation \"android.arch.paging:runtime:1.0.0-rc1\" // Test helpers for LiveData testImplementation \"android.arch.core:core-testing:1.1.1\" // Test helpers for Room testImplementation \"android.arch.persistence.room:testing:1.0.0\" } Synchronizujemy i budujemy projekt, sprawdzając, czy nie ma błędów kompilacji :). ","date":"292929-09-00","objectID":"/posts/2018-04-29-viewmodel/:2:1","tags":null,"title":"[OLD] ISS, Architecture: ViewModel, LiveData, Retrofit","uri":"/posts/2018-04-29-viewmodel/"},{"categories":["blog"],"content":"Resources Nasza aplikacja będzie bardzo prosta, więc możemy od razu ustawić potrzebne pliki w katalogu res. W strings.xml dodajemy kilka Stringów: \u003cresources\u003e \u003cstring name=\"app_name\"\u003eWhereIsSpaceStation\u003c/string\u003e \u003cstring name=\"header_note\"\u003eWhere is the International Space Station now?\u003c/string\u003e \u003cstring name=\"button_text\"\u003eCheck!\u003c/string\u003e \u003cstring name=\"response_empty\"\u003eIt seems we did not receive any data this time.\u003c/string\u003e \u003cstring name=\"response_failure\"\u003eIt seems you have some internet connection problems.\u003c/string\u003e \u003c/resources\u003e A w pliku XML naszego Activity (MainActivity.xml): \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003candroid.support.constraint.ConstraintLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:app=\"http://schemas.android.com/apk/res-auto\" xmlns:tools=\"http://schemas.android.com/tools\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" tools:context=\".MainActivity\"\u003e \u003cTextView android:id=\"@+id/header\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:text=\"@string/header_note\" android:textSize=\"16sp\" app:layout_constraintBottom_toTopOf=\"@id/coordinates\" app:layout_constraintLeft_toLeftOf=\"parent\" app:layout_constraintRight_toRightOf=\"parent\" app:layout_constraintTop_toTopOf=\"parent\" /\u003e \u003cTextView android:id=\"@+id/coordinates\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:text=\"\" app:layout_constraintBottom_toTopOf=\"@id/checkButton\" app:layout_constraintLeft_toLeftOf=\"parent\" app:layout_constraintRight_toRightOf=\"parent\" app:layout_constraintTop_toBottomOf=\"@id/header\" /\u003e \u003cButton android:id=\"@+id/checkButton\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:text=\"@string/button_text\" app:layout_constraintTop_toBottomOf=\"@id/coordinates\" app:layout_constraintBottom_toBottomOf=\"parent\" app:layout_constraintLeft_toLeftOf=\"parent\" app:layout_constraintRight_toRightOf=\"parent\"/\u003e \u003c/android.support.constraint.ConstraintLayout\u003e Na nasze UI składać się będzie (oprócz paska aplikacji): TextView z na sztywno ustawionym tekstem (“Where is the ISS now?”), TextView, w którym wyświetlać będziemy lokalizację ISS oraz Button, którego naciśnięcie zaktualizuje dane o lokalizacji. ","date":"292929-09-00","objectID":"/posts/2018-04-29-viewmodel/:2:2","tags":null,"title":"[OLD] ISS, Architecture: ViewModel, LiveData, Retrofit","uri":"/posts/2018-04-29-viewmodel/"},{"categories":["blog"],"content":"Konfiguracja Retrofit Ustawienie Retrofit jest bardzo proste. Potrzebujemy adresu, pod który wysyłane będzie żądanie, POJO, w których Retrofit będzie zapisywać dane zwrotne i jednego interfejsu. OpenNotify, API z którego skorzystamy, jest bardzo przyjemne, bo nie wymaga żadnej autoryzacji. Adres, pod którym znajdują się potrzebne nam dane o lokalizacji ISS jest taki: http://api.open-notify.org/iss-now.json. Jak widać, dane zwrotne są w postaci JSON, będziemy musieli poinformować o tym Retrofit przy konfiguracji. POJO wraz z anotacjami możemy wykreować automatycznie. W Android Studio istnieje możliwość używania pluginów. Klikamy w Preferences-\u003ePlugins, wpisujemy Json2Pojo, instalujemy i restartujemy IDE. {: .align-center} Stworzymy sobie osobną paczkę do POJO. W widoku struktury projektu z lewej strony programu klikamy na główną paczkę naszego projektu prawym przyciskiem myszy, następnie New-\u003ePackage. Nazywamy ją “pojos”. Klikamy prawym na pojos, New-\u003eCreate POJOs from JSON. W Root Class Name wpisujemy nazwę naszego POJO: IssLocationJSON, a w okienku przeklejamy JSON z OpenNotify. Klikamy OK. Plugin powinien wygenerować dwie klasy: IssLocationJSON oraz IssPosition. Dla porównania, kod dla IssLocationJSON: @Generated(\"net.hexar.json2pojo\") @SuppressWarnings(\"unused\") public class IssLocationJSON { @SerializedName(\"iss_position\") private IssPosition mIssPosition; @SerializedName(\"message\") private String mMessage; @SerializedName(\"timestamp\") private Long mTimestamp; public IssPosition getIssPosition() { return mIssPosition; } public void setIssPosition(IssPosition issPosition) { mIssPosition = issPosition; } public String getMessage() { return mMessage; } public void setMessage(String message) { mMessage = message; } public Long getTimestamp() { return mTimestamp; } public void setTimestamp(Long timestamp) { mTimestamp = timestamp; } } Oraz dla IssPosition: @Generated(\"net.hexar.json2pojo\") @SuppressWarnings(\"unused\") public class IssPosition { @SerializedName(\"latitude\") private String mLatitude; @SerializedName(\"longitude\") private String mLongitude; public String getLatitude() { return mLatitude; } public void setLatitude(String latitude) { mLatitude = latitude; } public String getLongitude() { return mLongitude; } public void setLongitude(String longitude) { mLongitude = longitude; } } W głównym folderze z kodem źródłowym, czyli obok paczki pojos, tworzymy paczkę api. W niej tworzymy interfejs dla Retrofit o nazwie OpenNotifyService. Ma on tylko jedną metodę abstrakcyjną: getIssLocation(). Anotujemy ją Retrofitowym @GET, podając ścieżkę do interesującego nas node’u API (czyli co jest po slashu głównego adresu): public interface OpenNotifyService { @GET(\"iss-now\") Call\u003cIssLocationJSON\u003e getIssLocation(); } Mamy już interfejs, POJO i adres. Później zapiszemy dane zwrotne z lokalizacją w LiveData. LiveData nie ma jednak wbudowanego sposobu na radzenie sobie z żądaniami internetowymi. A co jeśli użytkownik nie będzie mieć połączenia internetowego albo serwer OpenNotify przestanie działać? Zwrócimy null? Dokumentacja sugeruje takie rozwiązanie, ale na nasze minimalne potrzeby wystarczy dużo prostsze. Zrobimy wrapper dla naszych IssLocationJSON, posiadający pole informujące nas o stanie połączenia. Instancje tego wrappera zapiszemy dopiero jako LiveData. Wówczas będziemy mieli dostęp do informacji, czy posiadamy dane o lokalizacji ISS, czy też ich nie mamy, bez problemów z nullami. W paczce pojos tworzymy klasę IssLocationWrapper: package whereisspacestation.com.tryouts.whereisspacestation.pojos; public class IssLocationWrapper { private IssLocationJSON mIssLocationJson; private int mResponseStatus; public IssLocationJSON getIssLocationJson() { return mIssLocationJson; } public void setIssLocationJson(IssLocationJSON mIssLocationJson) { this.mIssLocationJson = mIssLocationJson; } public int getResponseStatus() { return mResponseStatus; } public void setResponseStatus(int mResponseStatus) { this.mResponseStatus = mResponseStatus; } ","date":"292929-09-00","objectID":"/posts/2018-04-29-viewmodel/:2:3","tags":null,"title":"[OLD] ISS, Architecture: ViewModel, LiveData, Retrofit","uri":"/posts/2018-04-29-viewmodel/"},{"categories":["blog"],"content":"Repository Możemy już stworzyć instancję klasy Retrofit, która będzie zczytywać dane o lokalizacji ISS z serwera. Mając w pamięci diagram przepływu danych z komponentami architektury Androida, musimy stworzyć Repository. Tworzymy paczkę repository, a w niej klasę IssLocationRepository: public class IssLocationRepository { private static final String BASE_URL = \"http://api.open-notify.org/\"; private static Retrofit mRetrofit; private static OpenNotifyService service; private MutableLiveData\u003cIssLocationWrapper\u003e mSpaceStationLocation; public IssLocationRepository() { mRetrofit = new Retrofit.Builder() .baseUrl(BASE_URL) .addConverterFactory(GsonConverterFactory.create()) .build(); service = mRetrofit.create(OpenNotifyService.class); mSpaceStationLocation = new MutableLiveData\u003c\u003e(); setLocation(); } public void setLocation() { final IssLocationWrapper issLocationWrapper = new IssLocationWrapper(); service.getIssLocation().enqueue(new Callback\u003cIssLocationJSON\u003e() { @Override public void onResponse(Call\u003cIssLocationJSON\u003e call, Response\u003cIssLocationJSON\u003e response) { if(response.isSuccessful()) { IssLocationJSON location = response.body(); if(location != null) { issLocationWrapper.setIssLocationJson(location); issLocationWrapper.setResponseStatus(Status.getResponseOk()); mSpaceStationLocation.postValue(issLocationWrapper); } else { issLocationWrapper.setResponseStatus(Status.getResponseEmpty()); mSpaceStationLocation.postValue(issLocationWrapper); } } else { issLocationWrapper.setResponseStatus(Status.getResponseEmpty()); mSpaceStationLocation.postValue(issLocationWrapper); } } @Override public void onFailure(Call\u003cIssLocationJSON\u003e call, Throwable t) { issLocationWrapper.setResponseStatus(Status.getResponseFailure()); mSpaceStationLocation.postValue(issLocationWrapper); } }); } public MutableLiveData\u003cIssLocationWrapper\u003e getLocation() { return mSpaceStationLocation; } } Od razu korzystamy z LiveData (w tym wypadku MutableLiveData, które różni się tylko tym, że upublicznia nam metody do zapisu danych w LiveData), bo z metody getLocation() będzie korzystać ViewModel. W konstruktorze konfigurujemy Retrofit: podajemy bazowe URL API, informujemy, z jakiego konwertera ma korzystać (GSON w tym wypadku, z racji na stosowany w OpenNotify JSON), no i jakie żądania ma obsługiwać (nasz OpenNotifyService). Metoda setLocation() wykonuje żądanie GET asynchronicznie, stąd .enqueue i CallBack. Jeśli nie ma połączenia z internetem wywołana zostanie przeciążona metoda onFailure(). Metoda onResponse() natomiast zostanie wywołana, jeśli otrzymamy odpowiedź z serwera. Jeśli wartość response.isSuccesful() jest false, to najwyraźniej dostaliśmy odpowiedź 404, 500 albo inną odpowiedź błędu, ale nie dostaliśmy w odpowiedzi danych o lokalizacji ISS, na których nam zależało. Może też się zdarzyć, że nasze żądanie zostanie przesunięte pod inny adres, ale nie otrzymamy odpowiedzi o błędnym adresie, bo adres działa (nie ma pod nim żadnych istotnych dla nas danych). We wszystkich tych przypadkach, a także kiedy po prostu otrzymujemy interesujące nas dane (hurra), stosownie konfigurujemy obiekt MutableLiveData\u003cIssLocationWrapper\u003e. Nic więcej w naszym Repository nie musimy dodawać. ","date":"292929-09-00","objectID":"/posts/2018-04-29-viewmodel/:2:4","tags":null,"title":"[OLD] ISS, Architecture: ViewModel, LiveData, Retrofit","uri":"/posts/2018-04-29-viewmodel/"},{"categories":["blog"],"content":"ViewModel Konstrukcja i struktura ViewModel w naszym przypadku jest bardzo prosta: tworzymy nową klasę, rozszerzającą klasę ViewModel o nazwie LocationViewModel: public class LocationViewModel extends ViewModel { private IssLocationRepository mRepository; private MutableLiveData\u003cIssLocationWrapper\u003e mIssLocation; public LocationViewModel() { super(); mRepository = new IssLocationRepository(); mIssLocation = mRepository.getLocation(); } public MutableLiveData\u003cIssLocationWrapper\u003e getLocation() { return mIssLocation; } public void checkLocation() { mRepository.setLocation(); } } Nasz LocationViewModel jest w stanie zwrócić informację o lokalizacji ISS (getLocation()) oraz wysłać żądanie do repozytorium o ponowne ustalenie lokalizacji. ","date":"292929-09-00","objectID":"/posts/2018-04-29-viewmodel/:2:5","tags":null,"title":"[OLD] ISS, Architecture: ViewModel, LiveData, Retrofit","uri":"/posts/2018-04-29-viewmodel/"},{"categories":["blog"],"content":"UI, MainActivity Jesteśmy gotowi by przekazać dane do warstwy UI. Przypomnijmy, że na layout MainActivity składają się TextView, w którym wyświetlać będziemy lokalizację ISS oraz Button do odświeżania lokalizacji. MainActivity: public class MainActivity extends AppCompatActivity { private LocationViewModel mLocationViewModel; private TextView mLocationTextView; private Button mLocationCheckButton; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); mLocationTextView = findViewById(R.id.coordinates); mLocationViewModel = ViewModelProviders.of(this).get(LocationViewModel.class); mLocationViewModel.getLocation().observe(this, new Observer\u003cIssLocationWrapper\u003e() { @Override public void onChanged(@Nullable IssLocationWrapper issLocationWrapper) { switch(issLocationWrapper.getResponseStatus()) { case 1: mLocationTextView.setText( issLocationWrapper.getIssLocationJson().getIssPosition().getLatitude() + \" \" + issLocationWrapper.getIssLocationJson().getIssPosition().getLongitude()); break; case 0: mLocationTextView.setText(R.string.response_empty); break; case -1: mLocationTextView.setText(R.string.response_failure); break; default: mLocationTextView.setText(R.string.response_empty); break; } } }); mLocationCheckButton = findViewById(R.id.checkButton); mLocationCheckButton.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View v) { mLocationViewModel.checkLocation(); } }); } } LocationViewModel dostarcza nam metoda get() ViewModelProvidera (przypisanego do Activity), nie tworzymy ViewModeli ze ‘‘zwykłego’’ konstruktora. Następnie zaczynamy obserwować (observe()) dane zwracane z ViewModel w metodzie getLocation(). Jeśli pamiętamy sprzed chwili, zwraca ona nam MutableLiveData\u003cIssLocationWrapper\u003e, a więc nasz obiekt z informacjami o lokalizacji ISS oraz stanem połączenia. Jeśli dane te ulegną zmianie wywołana zostanie metoda onChanged() obserwatora. Sprawdzany jest status połączenia i stosownie uzupełniany TextView. Pod koniec metody onCreate() mamy jeszcze zdefiniowany listener dla przycisku, obsługujący naciskanie przycisku przez użytkownika. Zauważmy, że nie wywołuje on już metody pobierającej dane z ViewModelu, a jedynie metodę aktualizacją lokalizację w samym LiveData w ViewModelu. Jako, że stan tego obiektu obserwujemy, to po zmianie jego zawartości automatycznie ujrzymy zmianę na poziomie UI w TextView. ","date":"292929-09-00","objectID":"/posts/2018-04-29-viewmodel/:2:6","tags":null,"title":"[OLD] ISS, Architecture: ViewModel, LiveData, Retrofit","uri":"/posts/2018-04-29-viewmodel/"},{"categories":["blog"],"content":"Finisz I to tyle, po odpaleniu aplikacji, zakładając dostęp do internetu, ujrzymy obrazek z początku artykułu: {: .align-center} Jeśli zaś włączymy w emulatorze/telefonie tryb samolotowy, to ujrzymy: {: .align-center} Podsumowując, zbudowaliśmy prostą aplikację, korzystającą z bibliotek Architecture Components oraz Retrofit. Warstwa UI jest odseparowana od reszty poprzez ViewModel. Wyświetlana informacja o lokalizacji ISS pochodzi z obserwowanego z poziomu UI obiektu LiveData przekazywanego przez ViewModel. ViewModel pozyskuje potrzebne informacje z Repository. W Repository wykonujemy połączenie z API przez Retrofit. UI nie wie, jak przetwarzane i skąd źródłowo pochodzą dane do wyświetlenia. ViewModel również na dobrą sprawę nie wie. Repository i ViewModel pozbawione są odwołań do klas związanych z UI. Warstwa UI natomiast pozbawiona jest odwołań do klas bezpośrednio związanych z logiką manipulacji i pozyskiwania danych. ","date":"292929-09-00","objectID":"/posts/2018-04-29-viewmodel/:2:7","tags":null,"title":"[OLD] ISS, Architecture: ViewModel, LiveData, Retrofit","uri":"/posts/2018-04-29-viewmodel/"},{"categories":["blog"],"content":"[This is a post from my old website. Outdated packages and libraries. Viewer discretion is advised ;-)] ","date":"131313-09-00","objectID":"/posts/2018-04-13-angularjs-spotibar/:0:0","tags":null,"title":"[OLD] SpotiBar: ANGULARJS","uri":"/posts/2018-04-13-angularjs-spotibar/"},{"categories":["blog"],"content":"PART 1 Zgodnie z poprzednim wpisem, rozbierzemy SpotiBar w wersji JavaScript na czynniki pierwsze. Użyjemy AngularJS, JavaScript i API Spotify. Jako że to pierwszy kontakt z JavaScriptem jako takim i choć budowana przez nas aplikacja pewnie nie spełnia kryteriów dobrego kodu, to przynajmniej pokazuje, że mimo Mnogości JS-owych frameworków i możliwości, rozpoczęcie zabawy w developerkę nie jest trudne. ","date":"131313-09-00","objectID":"/posts/2018-04-13-angularjs-spotibar/:1:0","tags":null,"title":"[OLD] SpotiBar: ANGULARJS","uri":"/posts/2018-04-13-angularjs-spotibar/"},{"categories":["blog"],"content":"Użyte frameworki JavaScript i narzędzia JavaScript AngularJS 1.6.x (na ten moment jest to wersja 1.6.9) Kilka paczek Angularowych: angularjs-slider, checklist-model, angular-spotify Konto developerskie na Spotify Terminal, przeglądarka i edytor tekstu ","date":"131313-09-00","objectID":"/posts/2018-04-13-angularjs-spotibar/:1:1","tags":null,"title":"[OLD] SpotiBar: ANGULARJS","uri":"/posts/2018-04-13-angularjs-spotibar/"},{"categories":["blog"],"content":"Ustawiamy workflow Potrzebujemy małego serwera, żeby obsługiwać zwroty z serwera Spotify. Na Macu sprawa jest prosta, bo mamy preinstalowanego Pythona. Serwer lokalny odpalamy komendą ‘python -m SimpleHTTPServer 8888’, gdzie pod 8888 możemy wstawić interesujący nas port. {: .align-center} Alternatywne rozwiązania: atom-live-server, dla użytkowników edytora Atom Live Server, dla użytkowników edytora Visual Studio Code (pomimo kilkudniowych prób, nie udało mi się za jego pomocą obsłużyć callbacku od Spotify) MAMP i podobne Jeżeli używamy sposobu terminalowego, to trzeba pamiętać o odpaleniu komendy w katalogu naszego projektu, a nie np. w katalogu domowym. Mając już prosty serwer możemy stworzyć folder projektu z podfolderami: app (w nim folder lib) i views. Struktura projektu jest konwencją, ale że ze ścieżek do plików będziemy korzystać, to warto pamiętać, gdzie jest jaki plik. Ostatni krok to zarejestrowanie aplikacji w konsoli Spotify. Wchodzimy w My Apps i po zalogowaniu tworzymy nową aplikację. {: .align-center} Następnie w jej ustawieniach dodajemy adres do callbacku, który będziemy potrzebować, by obsłużyć autoryzację ze strony Spotify. (możemy wpisać adres serwera lokalnego, pamiętając jednak, by kierował on na ten port, na który mamy ustawiony serwer). ![image-center](/images/oldblog/spotify_callback_url.jpg{: .align-center} Na koniec kwestia bibliotek Angularowych. Można je ściągnąć z podlinkowanych wcześniej stron. Na repozytorium aplikacji też są wrzucone, więc równie dobrze można je pobrać stąd. Obojętnie skąd je weźmiemy, mają wylądować w katalogu app/lib. ","date":"131313-09-00","objectID":"/posts/2018-04-13-angularjs-spotibar/:1:2","tags":null,"title":"[OLD] SpotiBar: ANGULARJS","uri":"/posts/2018-04-13-angularjs-spotibar/"},{"categories":["blog"],"content":"PART 2 Drogą przypomnienia, mamy przygotowane biblioteki JavaScriptowe, strukturę folderów projektu(*) utworzoną aplikację w konsoli dewelopera Spotify i serwer. Odpalamy serwer w katalogu naszego projektu. *Oprócz wspomnianych w poprzednim wpisie plików, skopiować można również ten plik CSS. Wtedy na ekranie powinno się pojawiać dokładnie to samo :). ","date":"131313-09-00","objectID":"/posts/2018-04-13-angularjs-spotibar/:2:0","tags":null,"title":"[OLD] SpotiBar: ANGULARJS","uri":"/posts/2018-04-13-angularjs-spotibar/"},{"categories":["blog"],"content":"Bazowy plik index.html Użytkownik naszej prostej aplikacji będzie de facto przemieszczać się pomiędzy dwoma stronami: na jednej będzie ustalać kryteria wyszukiwania rekomendacji, na drugiej zaś wyświetlane będą wyniki. Nie będziemy do tego celu tworzyć osobnych pełnoprawnych plików HTML, tylko skorzystamy z obecnej w AngularJS możliwości dynamicznego podmieniania elementów HTML. Naszym bazowym plikiem będzie umieszczony w wyjściowym folderze naszego projektu plik index.html. Pełen kod źródłowy znajduje się w repozytorium, tutaj opiszę tylko kluczowe kwestie. Oznaczenie Angularowe pojawia się już w pierwszym znaczniku: \u003chtml ng-app=\"spotiBar\"\u003e ng-app mówi Angularowi jaki jest najbardziej podstawowy element naszej aplikacji, rejestruje ją dla frameworku. Równie dobrze można w tym przypadku dać ten atrybut w elemencie body. W elemencie \u003chead\u003e mamy zbiór odwołań do plików .css i .js. Niektóre z nich mają standardową strukturę, przykładowo dla elementu script jest podana ścieżka do pliku w określonej lokalizacji na dysku. Dla celów pokazowych, nie wszystkie pliki są tak ładowane :). Na przykład pliki Bootstrapowe są ładowane z serwerów Bootstrapa, nie z dysku. Ma to swoje plusy i minusy, z jednej strony jest szansa, że takie korzystanie z CDN (content delivery network) pozwoli na szybsze załadowanie strony. Z drugiej strony, jak serwery, na których jest dany plik umieszczony, się posypią, to nasza strona też może ucierpieć. Ostatnią sprawą jest znacznik \u003cbase /\u003e. Ułatwia on życie, pozwalając na zdefiniowanie adresu bazowego naszej strony internetowej. Pozostawienie go na / oznacza, że podstrony będą się ładować na zasadzie: www.example.com/podstrona Zaś ustawienie \u003cbase href=\"/bazowylink/\"/\u003e spowoduje, że strony będą szukane pod: www.example.com/bazowylink/podstrona \u003chead\u003e \u003ctitle\u003eSpotiBar\u003c/title\u003e \u003cbase href=\"/\"\u003e \u003clink rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css\" integrity=\"sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm\" crossorigin=\"anonymous\"\u003e \u003clink href=\"https://fonts.googleapis.com/css?family=Lobster\" rel=\"stylesheet\"\u003e \u003clink href=\"https://fonts.googleapis.com/css?family=Cabin\" rel=\"stylesheet\"\u003e \u003clink rel=\"stylesheet\" href=\"app/style.css\"\u003e \u003cscript src=\"https://code.jquery.com/jquery-3.2.1.slim.min.js\" integrity=\"sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN\" crossorigin=\"anonymous\"\u003e\u003c/script\u003e \u003cscript src=\"https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js\" integrity=\"sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q\" crossorigin=\"anonymous\"\u003e\u003c/script\u003e \u003cscript src=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js\" integrity=\"sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl\" crossorigin=\"anonymous\"\u003e\u003c/script\u003e \u003cscript src=\"app/lib/angular.min.js\"\u003e\u003c/script\u003e \u003cscript src=\"app/lib/angular-route.min.js\"\u003e\u003c/script\u003e \u003cscript src=\"app/lib/checklist-model.js\"\u003e\u003c/script\u003e \u003cscript src=\"app/lib/angular-spotify.min.js\"\u003e\u003c/script\u003e \u003clink rel=\"stylesheet\" type=\"text/css\" href=\"app/lib/rzslider.min.css\" /\u003e \u003cscript src=\"app/lib/rzslider.min.js\"\u003e\u003c/script\u003e \u003cscript src=\"app/app.js\"\u003e\u003c/script\u003e \u003c/head\u003e W tym momencie zrobimy tylko pasek nawigacyjny z przyciskiem do logowania. Kod wygląda tak: \u003cnav ng-controller=\"LoginController\" class=\"navbar navbar-inverse altnavbg\" role=\"navigation\"\u003e \u003cdiv class=\"container-fluid\"\u003e \u003cdiv class=\"navbar-header\"\u003e \u003ca class=\"navbar-brand\" href=\"/#!/search\"\u003eSpotiBar - Advanced Spotify Search\u003c/a\u003e \u003c/div\u003e \u003cul class=\"nav navbar-nav navbar-right\"\u003e \u003cbutton type=\"button\" class=\"btn btn-default navbar-btn\" ng-click=\"login()\"\u003eLogin\u003c/button\u003e \u003c/ul\u003e \u003c/div\u003e \u003c/nav\u003e Prawie wszystkie atrybuty elementów są Bootstrapowe i nie będziemy ich w tym miejscu tłumaczyć. Dokumentacja Bootstrapa jest przyjazna użytkownikowi :). Natomiast kilka rzeczy jest Angularowych. Atrybut ng-controller jest dyrektywą Angulara. Określa jaki fragment kodu będzie obsługiwać wskazaną część strony","date":"131313-09-00","objectID":"/posts/2018-04-13-angularjs-spotibar/:2:1","tags":null,"title":"[OLD] SpotiBar: ANGULARJS","uri":"/posts/2018-04-13-angularjs-spotibar/"},{"categories":["blog"],"content":"Autoryzacja OAuth Do korzystania z API Spotify użytkownik musi przejść przez proces autoryzacji. Uwierzytelnienie polega na wysłaniu żądania wraz z kluczem naszej aplikacji i odebraniu tokena zwrotnego. Token musi być następnie dołączany do wysyłanych przez użytkownika kolejnych zapytań do API. Do komunikacji z API skorzystamy z przygotowanego pod AngularJS angular-spotify. callback.html Potrzebujemy prostego pliku HTML, do którego Spotify będzie odsyłać token po skończonej autoryzacji. Autor angular-spotify dostarcza templatkę takowego pliku, o tutaj. Wystarczy nam ona w zupełności. Kopiujemy ją do głównego folderu naszego projektu. Autoryzacja przebiega żądaniem GET, więc ten mały skrypcik w pliku callback.html patrzy po pasku adresowym okna i, jeżeli go znajdzie, zapisuje token w pamięci przeglądarki (localStorage) i zamyka okno, a jeśli nie to tylko zamyka okno. W poprzednim wpisie ustawialiśmy Redirect URI dla naszej aplikacji Spotify (w konsoli dewelopera). Jeżeli zmienimy nazwę callback.html na coś innego, to musimy również w ustawieniach aplikacji zmienić przekierowanie. app.js Zakładając, że w naszym pliku index.html mamy wszystko to, co powyżej opisane, tworzymy nowy plik: app.js w folderze app. W pierwszej kolejności, musimy stworzyć instancję naszej aplikacji (w zasadzie - moduł) dla AngularJS. Składnia wygląda tak: const spotiBar = angular.module(\"spotiBar\", [ \"spotify\" ]); O ile w pliku index.html nadaliśmy wartość spotiBar atrybutowi ng-app, to tutaj musi się pojawić ta sama nazwa. W nawiasie kwadratowym wymieniamy paczki, z których będziemy korzystać. Póki co będziemy korzystać tylko z “spotify” właśnie :). Resztę dodamy później. Następnie czeka nas odrobinę konfiguracji: spotiBar.config([ \"SpotifyProvider\", function(SpotifyProvider) { SpotifyProvider.setClientId(\"CLIENT_ID\"); SpotifyProvider.setRedirectUri(\"http://localhost:8080/callback.html\"); SpotifyProvider.setScope(\"playlist-read-private\"); if (localStorage.getItem(\"spotify-token\")) { SpotifyProvider.setAuthToken(localStorage.getItem(\"spotify-token\")); console.log(\"Token got from localStorage.\"); } else { console.log(\"There was no token in localStorage.\"); } } ]); W nawiasie kwadratowym wymieniamy, ponownie, zależności (w tym wypadku SpotifyProvider z angular-spotify), a następnie implementujemy funkcję konfiguracyjną. Pod CLIENT_ID podajemy client id wzięty ze strony naszej aplikacji w konsoli dewelopera Spotify (NIE secret, tylko “zwykły”). Pod .setRedirectUriwklepujemy adres do callbacku, zgodny z naszym serwerem lokalnym, nazwą pliku callbackowego, oraz zgodny z tym, który wpisaliśmy w ustawieniach aplikacji w konsoli Spotify*****. Pod .setScope definiujemy jakie upoważnienia użytkownik naszej aplikacji ma nam nadać (dla celów przykładowych u nas jest to odczytanie jego prywatnych playlist). Pełny zestaw scope’ów znaleźć można tutaj. Wyrażenie warunkowe if sprawdza, czy w pamięci lokalnej przeglądarki jest już token. Jeśli tak, zapisujemy go do SpotifyProvidera i dostajemy zwrotny komunikat w konsoli. Jeśli nie, to czeka nas tylko komunikat zwrotny w konsoli ;). Ok. Brakuje nam tylko jednej rzeczy: kodu kontrolera, odpowiedzialnego za logowanie użytkownika! spotiBar.controller(\"LoginController\", [ \"$scope\", \"Spotify\", function($scope, Spotify) { $scope.login = function() { Spotify.login().then( function(data) { console.log(data); Spotify.setAuthToken(data); alert(\"You are now logged in\"); }, function() { console.log(\"didn't log in\"); } ); }; } ]); Podobnie jak poprzednio, na początku nawiasu kwadratowego wymieniamy potrzebne zależności ($scope i Spotify). $scope to obiekt w Angular pozwalający na komunikację pomiędzy HTML a JS. Czyli pisząc $scope.login =, definiujemy funkcję, do której w pliku index.html odwoływaliśmy się pisząc ng-click=login(). Funkcja Spotify.login(), z kolei, to metoda z angular-spotify, wysyłająca żądanie autoryzacji do Spotify. Po zakończeniu autoryzacji, o ile zakończyła się sukcesem, zapisuje informację o tokenie w obiekcie S","date":"131313-09-00","objectID":"/posts/2018-04-13-angularjs-spotibar/:2:2","tags":null,"title":"[OLD] SpotiBar: ANGULARJS","uri":"/posts/2018-04-13-angularjs-spotibar/"},{"categories":["blog"],"content":"Logujemy się Jeśli nasz serwer nadal jest włączony to wchodzimy na nasze http://localhost:8888 (ew. inny port) i patrzymy. Zakładając, że mamy te same pliki CSS, powinno to wyglądać tak: {: .align-center} Gdy klikniemy w przycisk “Login”, wyskoczy okienko proszące o potwierdzenie (ew. zalogowanie do Spotify, jeśli nie byliście w przeglądarce zalogowani). Po jego kliknięciu, przekierowanie pchnie token do callback.html, okienko zniknie, a nam ukaże się: {: .align-center} Token ma termin ważności, gdy się wyczerpie, będziemy musieli zalogować się ponownie (inne metody autoryzacji pozwalają na odświeżanie tokenu, w angular-spotify tego nie ma). Następnym razem zajmiemy się stworzeniem widoku z kryteriami wyszukiwania :). (*) Jeśli okienko z autoryzacją się samo nie zamyka, tylko pojawia się błąd 404 albo informacja o złym redirect_uri, to trzeba pokombinować trochę z ustawieniem adresu callbacku w konsoli dewelopera Spotify, i ustawieniami w naszej konfiguracji SpotifyProvider. Raz mi działa, kiedy podaję bezpośrednio z końcówką “.html”, a raz bez. … ;) ","date":"131313-09-00","objectID":"/posts/2018-04-13-angularjs-spotibar/:3:0","tags":null,"title":"[OLD] SpotiBar: ANGULARJS","uri":"/posts/2018-04-13-angularjs-spotibar/"},{"categories":["blog"],"content":"PART 3 W tym odcinku dodamy do naszej aplikacji formularz, zbierający kryteria wyszukiwania oraz widokiem wyświetlającym rezultaty. ","date":"131313-09-00","objectID":"/posts/2018-04-13-angularjs-spotibar/:4:0","tags":null,"title":"[OLD] SpotiBar: ANGULARJS","uri":"/posts/2018-04-13-angularjs-spotibar/"},{"categories":["blog"],"content":"index.html Jako, że chcemy by Angular sam uzupełniał DOM o potrzebne elementy HTML, musimy oznaczyć miejsce, w którym ma to robić. Służy temu dyrektywa ng-view. W pliku index.html pod elementem \u003cnav\u003e\u003c/nav\u003e dodajemy: \u003cmain ng-view\u003e ","date":"131313-09-00","objectID":"/posts/2018-04-13-angularjs-spotibar/:4:1","tags":null,"title":"[OLD] SpotiBar: ANGULARJS","uri":"/posts/2018-04-13-angularjs-spotibar/"},{"categories":["blog"],"content":"app.js (2) By scedować zarządzanie przekierowaniami na stronie Angularowi musimy skonfigurować moduł AngularJS, który domyślnie nie jest ładowany: ngRoute. Zmodyfikujemy w tym celu pierwszą linijkę pliku app.js, w której inicjowaliśmy naszą aplikację: const spotiBar = angular.module(\"spotiBar\", [ \"ngRoute\", \"checklist-model\", \"rzModule\", \"spotify\" ]); Oprócz ngRoute dodaliśmy od razu checklist-model oraz rzModule, czyli dodatkowe biblioteki, które ułatwią nam pracę z formularzami. ngRoute trzeba stosownie skonfigurować, do naszej funkcji konfigurującej dodajemy: spotiBar.config([ \"$routeProvider\", \"SpotifyProvider\", function($routeProvider, SpotifyProvider) { $routeProvider .when(\"/\", { redirectTo: \"/search\" }) .when(\"/search\", { templateUrl: \"views/search.html\", controller: \"SearchController\" }) .when(\"/results\", { templateUrl: \"views/results.html\", controller: \"ResultsController\" }); // Poniżej reszta z poprzednich części: SpotifyProvider.setClientId().... // A także sprawdzenie obecności tokena w localStorage: if(localStorage.getItem()).... } ]); Dzięki temu, kiedy użytkownik kliknie link odsyłający do, dajmy na to, /search, Angular będzie wiedział jaki fragment HTML ma dodać w miejsce naszego ng-view w index.html (będzie to fragment zlokalizowany w views/search.html) oraz jaki kontroler jest tam używany (SearchController). Przypadek .when(\"/\", {}) to przypadek wejścia na stronę główną. Również wtedy Angular ma załadować to samo, co w momencie przekierowania na /search. ","date":"131313-09-00","objectID":"/posts/2018-04-13-angularjs-spotibar/:4:2","tags":null,"title":"[OLD] SpotiBar: ANGULARJS","uri":"/posts/2018-04-13-angularjs-spotibar/"},{"categories":["blog"],"content":"search.html Tworzymy plik search.html w folderze /views. Kod formularza wyszukiwania jest dosyć długi, gdyż jest wiele kryteriów, które użytkownik może ustawić. \u003cdiv class=\" row justify-content-center\"\u003e \u003cbutton type=\"button\" class=\"btn-primary\" ng-click=\"searchRecommendations()\"\u003eSearch recommendations\u003c/button\u003e \u003c/div\u003e \u003cdiv class=\"container row\"\u003e \u003cdiv class=\"col-md-1\"\u003e\u003c/div\u003e \u003cdiv class=\"col-md-4\"\u003e \u003cdiv class=\"form-group \"\u003e \u003cform\u003e \u003cinput type=\"submit\" ng-click=\"searchSeeds()\" class=\"btn-warning\" value=\"Search for seeds\"\u003e \u003cinput type=\"text\" ng-model=\"seedsQuery\" placeholder=\"Enter seeds query\"/\u003e \u003clabel class=\"spotify-font-color\"\u003eLimit (1-100): \u003cinput type=\"number\" min=\"1\" max=\"100\" ng-model=\"limit\" /\u003e \u003c/label\u003e \u003cbr /\u003e \u003clabel class=\"spotify-font-color\"\u003eDuration (in seconds): \u003cinput type=\"number\" ng-model=\"duration\" /\u003e \u003c/label\u003e \u003cbr /\u003e \u003clabel class=\"spotify-font-color\"\u003eKey (0 = C, 2 = D, and so on): \u003cinput type=\"number\" min=\"0\" max=\"11\" value=\"0\" ng-model=\"key\" /\u003e \u003c/label\u003e \u003cbr /\u003e \u003clabel class=\"spotify-font-color\"\u003eMajor/Minus (1/0): \u003cinput type=\"number\" min=\"0\" max=\"1\" value=\"0\" ng-model=\"ismajor\" /\u003e \u003c/label\u003e \u003cbr /\u003e \u003clabel class=\"spotify-font-color\"\u003eTempo (BPM): \u003cinput type=\"number\" min=\"0\" max=\"1000\" value=\"120\" ng-model=\"tempo\" /\u003e \u003c/label\u003e \u003cbr /\u003e \u003cdiv\u003e \u003clabel class=\"spotify-font-color\"\u003eAcousticness: \u003cinput type=\"text\" ng-model=\"sliderAcousticness\" /\u003e \u003c/label\u003e \u003cbr/\u003e \u003crzslider rz-slider-model=\"sliderAcousticness\" rz-slider-options=\"{floor: 0, ceil: 100, step: 1, showSelectionBar: true}\"\u003e\u003c/rzslider\u003e \u003c/div\u003e \u003cdiv\u003e \u003clabel class=\"spotify-font-color\"\u003eDanceability: \u003cinput type=\"text\" min=\"0\" max=\"100\" ng-model=\"sliderDanceability\" /\u003e \u003c/label\u003e \u003crzslider rz-slider-model=\"sliderDanceability\" rz-slider-options=\"{floor: 0, ceil: 100, step: 1, precision: 1}\"\u003e\u003c/rzslider\u003e \u003c/div\u003e \u003cdiv\u003e \u003clabel class=\"spotify-font-color\"\u003eEnergy: \u003cinput type=\"text\" min=\"0\" max=\"100\" ng-model=\"sliderEnergy\" /\u003e \u003c/label\u003e \u003crzslider rz-slider-model=\"sliderEnergy\" rz-slider-options=\"{floor: 0, ceil: 100, step: 1, precision: 1}\"\u003e\u003c/rzslider\u003e \u003c/div\u003e \u003cdiv\u003e \u003clabel class=\"spotify-font-color\"\u003eLiveness: \u003cinput type=\"text\" min=\"0\" max=\"100\" ng-model=\"sliderLiveness\" /\u003e \u003c/label\u003e \u003crzslider rz-slider-model=\"sliderLiveness\" rz-slider-options=\"{floor: 0, ceil: 100, step: 1, precision: 1}\"\u003e\u003c/rzslider\u003e \u003c/div\u003e \u003cdiv\u003e \u003clabel class=\"spotify-font-color\"\u003eInstrumentalness: \u003cinput type=\"text\" min=\"0\" max=\"100\" ng-model=\"sliderInstrumentalness\" /\u003e \u003c/label\u003e \u003crzslider rz-slider-model=\"sliderInstrumentalness\" rz-slider-options=\"{floor: 0, ceil: 100, step: 1, precision: 1}\"\u003e\u003c/rzslider\u003e \u003c/div\u003e \u003cdiv\u003e \u003clabel class=\"spotify-font-color\"\u003ePopularity: \u003cinput type=\"text\" min=\"0\" max=\"100\" ng-model=\"sliderPopularity\" /\u003e \u003c/label\u003e \u003crzslider rz-slider-model=\"sliderPopularity\" rz-slider-options=\"{floor: 0, ceil: 100, step: 1, precision: 1}\"\u003e\u003c/rzslider\u003e \u003c/div\u003e \u003cdiv\u003e \u003clabel class=\"spotify-font-color\"\u003eSpeechiness: \u003cinput type=\"text\" min=\"0\" max=\"100\" ng-model=\"sliderSpeechiness\" /\u003e \u003c/label\u003e \u003crzslider rz-slider-model=\"sliderSpeechiness\" rz-slider-options=\"{floor: 0, ceil: 100, step: 1, precision: 1}\"\u003e\u003c/rzslider\u003e \u003c/div\u003e \u003cdiv\u003e \u003clabel class=\"spotify-font-color\"\u003eValence: \u003cinput type=\"text\" min=\"0\" max=\"100\" ng-model=\"sliderValence\" /\u003e \u003c/label\u003e \u003crzslider rz-slider-model=\"sliderValence\" rz-slider-options=\"{floor: 0, ceil: 100, step: 1, precision: 1}\"\u003e\u003c/rzslider\u003e \u003c/div\u003e \u003c/form\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"col-md-7\"\u003e \u003cdiv class=\"form-group\"\u003e \u003c/div\u003e \u003cdiv class=\"container row\"\u003e \u003cdiv class=\"col-md-4\"\u003e \u003cp class=\"spotify-font-color\"\u003eArtists:\u003c/p\u003e \u003cdiv class=\"row\" ng-repeat=\"artist in seedsArtists\"\u003e \u003cinput type=\"checkbox\" checklist-model=\"seedsSelection.artists\" checklist-value=\"artist.id\" /\u003e \u003cspan class=\"spotify-font-color\"\u003e{{artist.name}}\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"col-md-6\"\u003e \u003cp class=\"spotify-font-color\"\u003eTracks:\u003c/p\u003e \u003cdiv class=\"row\" ng-repeat=\"track in seedsTracks\"\u003e \u003cinput type=\"checkbox\" checklist-model=\"seedsSelection.tracks\" checklist-value=\"track.id\" /\u003e \u003cspan class=\"spotify-font-color\"\u003e{{track.name}} -\u003c/span\u003e \u003cspan class=\"spot","date":"131313-09-00","objectID":"/posts/2018-04-13-angularjs-spotibar/:4:3","tags":null,"title":"[OLD] SpotiBar: ANGULARJS","uri":"/posts/2018-04-13-angularjs-spotibar/"},{"categories":["blog"],"content":"app.js SearchController Powracając do pliku app.js, zaczynamy pisać kod kontrolera: spotiBar.controller(\"SearchController\", [ \"$scope\", \"Spotify\", function($scope, Spotify) { // Tutaj będą funkcje kontrolera } ]); Jak widzimy, będziemy się odwoływać do obiektu $scope, pozwalającemu nam pobrać ustawione przez użytkownika kryteria, a w dalszym planie także wyświetlić użytkownikowi wyniki. Pierwsza funkcja, którą napiszemy, to obecna w search.html i przywołana już funkcja searchSeeds. W obrębie naszego kontrolera: let seedsSelection = {}; $scope.searchSeeds = function() { $scope.seedsSelection = seedsSelection; Spotify.getAvailableGenreSeeds().then( function(data) { $scope.seedsGenres = data.data.genres; }, function(error) { alert(\"The access token expired. Please login again.\"); } ); Spotify.search($scope.seedsQuery, \"artist\").then(function(data) { $scope.seedsArtists = data.data.artists.items; }); Spotify.search($scope.seedsQuery, \"track\").then(function(data) { $scope.seedsTracks = data.data.tracks.items; }); }; Tworzymy obiekt seedsSelection, będziemy w nim przetrzymywać wybrane przez użytkownika nazwy artystów/utworów/gatunków muzycznych. Wiążemy go z obecnym w $scope seedsSelection. Spotify API posiada szereg rodzajów zapytań do bazy. Jednym z nich jest żądanie zwrócenia listy dostępnych gatunków muzycznych. Do tej metody odwołujemy się w linijce 5. Jeśli zakończy się ona sukcesem, to zwrócona zostanie lista gatunków w formacie JSON w obiekcie data. Przypisujemy te dane do $scope.seedsGenres, a kod w search.html w linijkach 108-111 wyświetli je użytkownikowi. Dodatkowo kontrolujemy ewentualne wystąpienie błędu połączenia, będzie to oznaczać, że token uzyskany przez użytkownika w trakcie autoryzacji przestał być ważny i trzeba się zalogować na nowo. Analogicznie z zapytaniami o artystów i utwory, ale tutaj już tego sprawdzenia błędu nie obsługujemy, jako że wszystkie metody są wykonywane mniej więcej w tym samym czasie. Następną funkcję, dokonanie właściwego wyszukania rekomendacji, podzielimy na szereg funkcji: $scope.searchRecommendations = function() { if (checkIfSeedsInLimit()) { Spotify.getRecommendations(prepCriteria()).then( function(data) { //Zrób coś z wynikami wyszukania, np. wypisz je w konsoli przeglądarki. console.log(data); // Przekieruj okno przeglądarki pod widok z wynikami. document.location.href = \"/#!/results\"; }, function(error) { alert(\"The access token expired. Please login again.\"); } ); } else { alert(\"You can select up to 5 different seeds.\"); } }; checkIfSeedsInLimit = function() { if ( $scope.seedsSelection == undefined || ($scope.seedsSelection.artists == undefined \u0026\u0026 $scope.seedsSelection.tracks == undefined \u0026\u0026 $scope.seedsSelection.genres == undefined) ) { alert(\"You did not define any seeds\"); return false; } let numberOfSeeds = 0; if (!($scope.seedsSelection.artists == undefined)) { numberOfSeeds = numberOfSeeds + Object.keys($scope.seedsSelection.artists).length; } if (!($scope.seedsSelection.genres == undefined)) { numberOfSeeds = numberOfSeeds + Object.keys($scope.seedsSelection.genres).length; } if (!($scope.seedsSelection.tracks == undefined)) { numberOfSeeds = numberOfSeeds + Object.keys($scope.seedsSelection.tracks).length; } if (0 \u003c numberOfSeeds \u0026\u0026 5 \u003e= numberOfSeeds) { return true; } else { return false; } }; prepCriteria = function() { let criteria = {}; if ($scope.seedsSelection.artists != undefined) { criteria.seed_artists = $scope.seedsSelection.artists.join(); } if ($scope.seedsSelection.tracks != undefined) { criteria.seed_tracks = $scope.seedsSelection.tracks.join(); } if ($scope.seedsSelection.genres != undefined) { criteria.seed_genres = $scope.seedsSelection.genres.join(); } if ($scope.limit != null) { criteria.limit = $scope.limit; } if ($scope.duration != null) { criteria.target_duration_ms = $scope.duration; } if ($scope.key != null) { criteria.target_key = $scope.key; } if ($scope.ismajor != null) { criteria.target_mode = $scope.ismajor; } if ($scope.tempo != null) { cri","date":"131313-09-00","objectID":"/posts/2018-04-13-angularjs-spotibar/:4:4","tags":null,"title":"[OLD] SpotiBar: ANGULARJS","uri":"/posts/2018-04-13-angularjs-spotibar/"},{"categories":["blog"],"content":"ResultsController i SharingResultsService W AngularJS do tego celu służą Service (serwisy/usługi? Tutaj o nich więcej). Pozwalają one na komunikację pomiędzy kontrolerami. Na nasze potrzeby wystarczy bardzo prosta implementacja: // Service spotiBar.factory(\"SharingResultsService\", function() { let sharingRecommendationResults = { data: {} }; return sharingRecommendationResults; }); Kontrolery, które będą korzystać z SharingResultsService będą miały do dyspozycji obiekt sharingRecommendationResults. Na poziomie SearchControllera zapiszemy do tego obiektu wyniki wyszukiwania, zaś na poziomie ResultsController się do tych wyników odwołamy. Musimy zmodyfikować nieco nasz SearchController: spotiBar.controller(\"SearchController\", [ \"$scope\", \"Spotify\", \"SharingResultsService\", function($scope, Spotify, SharingResultsService) { // $scope.searchSeeds = function() .... $scope.searchRecommendations = function() { if (checkIfSeedsInLimit()) { Spotify.getRecommendations(prepCriteria()).then( function(data) { SharingResultsService.data = data.data; console.log(data); document.location.href = \"/#!/results\"; }, function(error) { alert(\"The access token expired. Please login again.\"); } ); } else { alert(\"You can select up to 5 different seeds.\"); } }; // reszta kodu kontrolera }]); Względem poprzedniej wersji dodaliśmy SharingResultsService jako zależność oraz zapisaliśmy (linijka 12) wyniki. ResultsController będzie bardzo krótki. W obiekcie data nasze wyniki są pod tracks: spotiBar.controller(\"ResultsController\", [ \"$scope\", \"SharingResultsService\", function($scope, SharingResultsService) { $scope.recommendedTracks = SharingResultsService.data.tracks; } ]); W naszym widoku wyników musimy ustawić odwołanie jako recommendedTracks. ","date":"131313-09-00","objectID":"/posts/2018-04-13-angularjs-spotibar/:4:5","tags":null,"title":"[OLD] SpotiBar: ANGULARJS","uri":"/posts/2018-04-13-angularjs-spotibar/"},{"categories":["blog"],"content":"Results.html Jako że jeszcze go nie stworzyliśmy, to zrobimy to teraz. Tworzymy plik results.html w folderze /views: \u003cdiv class=\"container\"\u003e \u003ch1 class=\"spotify-font-artist-name\"\u003eResults:\u003c/h1\u003e \u003cdiv class=\"justify-content-center row\"\u003e \u003cdiv class=\"col-lg-2 col-md-3 col-sm-6 col-xs-12 text-center\" ng-repeat=\"track in recommendedTracks\" style=\"padding-left: 5px;padding-right: 5px;\"\u003e \u003ca href=\"{{track.album.uri}}\"\u003e\u003cimg ng-src=\"{{track.album.images[1].url}}\" alt=\"\" style=\"width:170px;height:170px;\"\u003e\u003c/a\u003e \u003cbr/\u003e \u003cdiv class=\"text-center\"\u003e \u003cp style=\"margin-bottom: 0px;margin-top: 5px;\"\u003e \u003ca class=\"spotify-font-artist-name\" ng-repeat=\"artist in track.artists\" href=\"{{artist.uri}}\"\u003e{{artist.name}} \u003c/a\u003e \u003c/p\u003e \u003cp class=\"text-warning\" style=\"margin-bottom: 0px;\"\u003e\u003ca class=\"text-warning\" href=\"{{track.uri}}\"\u003e{{track.name}}\u003c/a\u003e\u003c/p\u003e \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e Pomijając klasy Bootstrapowe (sprawiające, że nasze wyniki będą wyświetlane w kilku responsywnych kolumnach), ustawiliśmy ng-repeat na iteracje utworów w recommendedTracks. Wyświetlana jest okładka albumu, nazwa utworu i wykonawcy. I to tyle! Po zapisaniu i odpaleniu na serwerze lokalnym powinniśmy widzieć coś takiego: Strona z kryteriami wyszukiwania: {: .align-center} Strona z wynikami: {: .align-center} I już! W następnej części poprawimy estetykę naszej aplikacji i dodamy instrukcję obsługi (mogliśmy od niej zacząć, właśnie sobie uświadomiłem, że użytkownik nie musi wiedzieć na czym polega wyszukiwanie rekomendacji w Spotify API ;)). ","date":"131313-09-00","objectID":"/posts/2018-04-13-angularjs-spotibar/:4:6","tags":null,"title":"[OLD] SpotiBar: ANGULARJS","uri":"/posts/2018-04-13-angularjs-spotibar/"},{"categories":["blog"],"content":"PART 4 W tym odcinku poprawimy nieco estetykę naszej aplikacji, dodamy instrukcję i ułatwimy UI. ","date":"131313-09-00","objectID":"/posts/2018-04-13-angularjs-spotibar/:5:0","tags":null,"title":"[OLD] SpotiBar: ANGULARJS","uri":"/posts/2018-04-13-angularjs-spotibar/"},{"categories":["blog"],"content":"Estetyka Skorzystamy z darmowej wersji Shards, upiększającej nieco domyślnego Bootstrapa. Tak było: {: .align-center} A tak będzie: {: .align-center} W samym wpisie wymienimy tylko najważniejsze zmiany, małe zmiany CSSowe pominę. Wszystko i tak jest na GitHub w nowszej wersji. Jest to bardziej wpis sprawozdawczy, niż poradnikowy. Zawsze można prześledzić historię repozytorium ;-). Search.html Zrezygnujemy z paczki rz-slider, na rzecz… niczego :). Slidery są mało wygodne, było ich za dużo i odciągały uwagę. Wyniki wyszukiwania z API też nie powalają precyzją, jeśli chodzi o kryteria, do których były suwaki… Zamiast tego są elementy select z kilkoma predefiniowanymi wartościami. Prawą połowę ekranu wyszukiwania zajmie instrukcja, która będzie wyświetlana tak długo, jak długo użytkownik nie wyszuka seedów. Odpowiadają za to dyrektywy ng-switch i ng-switch-when. Pełen kod dla search.html znajduje się poniżej: \u003cdiv class=\"container row mt-5 ml-5\"\u003e \u003cdiv class=\"col-md-6\"\u003e \u003clabel class=\"col-form-label-lg\"\u003e1. Choose up to five tracks/genres/artists: \u003c/label\u003e \u003cform class=\"form-inline\"\u003e \u003cdiv class=\"input-group input-group-lg mx-sm-3 mb-2\"\u003e \u003cdiv class=\"input-group-prepend\"\u003e \u003cspan class=\"input-group-text\"\u003eSeeds\u003c/span\u003e \u003c/div\u003e \u003cinput type=\"text\" class=\"form-control\" id=\"form-seeds\" placeholder=\"Type in seeds query\" ng-model=\"seedsQuery\"\u003e \u003cdiv class=\"input-group-append\"\u003e \u003cbutton type=\"button\" class=\"btn btn-outline-secondary\" ng-click=\"searchSeeds()\"\u003eFind seeds\u003c/button\u003e \u003c/div\u003e \u003c/div\u003e \u003c/form\u003e \u003clabel class=\"col-form-label-lg mr-5\"\u003e2. Search!\u003c/label\u003e \u003cbutton type=\"button\" class=\"btn btn-success btn-lg btn-block\" ng-click=\"searchRecommendations()\"\u003eFind tracks\u003c/button\u003e \u003clabel class=\"col-form-label-lg\"\u003e* Optional criteria\u003c/label\u003e \u003cform\u003e \u003cdiv class=\"form-row\"\u003e \u003cdiv class=\"form-group col-md-6\"\u003e \u003clabel for=\"inputDuration\" class=\"col-form-label-sm\"\u003eDuration: \u003c/label\u003e \u003cinput id=\"inputDuration\" type=\"number\" class=\"form-control input-group-sm\" ng-model=\"durationInput\" placeholder=\"Duration in ms (\u003e0)\"\u003e \u003c/div\u003e \u003cdiv class=\"form-group col-md-6\"\u003e \u003clabel for=\"inputLimit\" class=\"col-form-label-sm\"\u003eLimit: \u003c/label\u003e \u003cinput id=\"inputLimit\" type=\"number\" class=\"form-control input-group-sm\" ng-model=\"limitInput\" placeholder=\"1-100 results\"\u003e \u003c/div\u003e \u003c/div\u003e \u003c/form\u003e \u003cform\u003e \u003cdiv class=\"form-row mb-3\"\u003e \u003cdiv class=\"form-group col-md-6\"\u003e \u003clabel for=\"inputTempo\" class=\"col-form-label-sm\"\u003eTempo (BPM): \u003c/label\u003e \u003cinput id=\"inputTempo\" type=\"number\" class=\"form-control input-group-sm\" ng-model=\"tempoInput\" placeholder=\"Beats per minute (\u003e0)\"\u003e \u003c/div\u003e \u003cdiv class=\"form-group col-md-6\"\u003e \u003clabel for=\"inputKey\" class=\"col-form-label-sm\"\u003eKey: \u003c/label\u003e \u003cinput id=\"inputKey\" type=\"number\" class=\"form-control input-group-sm\" ng-model=\"keyInput\" placeholder=\"0 - C, 1 - C#, up to 11\"\u003e \u003c/div\u003e \u003c/div\u003e \u003c/form\u003e \u003cform\u003e \u003cdiv class=\"form-group row\"\u003e \u003clabel for=\"inputMajor\" class=\"col-sm-5 col-form-label\"\u003eMajor/Minor: \u003c/label\u003e \u003cdiv class=\"col-sm-7\"\u003e \u003cselect id=\"inputMajor\" class=\"custom-select\" ng-model=\"isMajorSelect\"\u003e \u003coption value=\"\"\u003eSelect....\u003c/option\u003e \u003coption value=\"1\"\u003eMajor\u003c/option\u003e \u003coption value=\"0\"\u003eMinor\u003c/option\u003e \u003c/select\u003e \u003c/div\u003e \u003c/div\u003e \u003c/form\u003e \u003cform\u003e \u003cdiv class=\"form-group row\"\u003e \u003clabel for=\"inputAcoustic\" class=\"col-sm-5 col-form-label\"\u003eAcousticness: \u003c/label\u003e \u003cdiv class=\"col-sm-7\"\u003e \u003cselect id=\"inputAcoustic\" class=\"custom-select\" ng-model=\"acousticnessSelect\" ng-options=\"x.level for x in criteriaOptions\"\u003e \u003coption value=\"\"\u003eSelect...\u003c/option\u003e \u003c/select\u003e \u003c/div\u003e \u003c/div\u003e \u003c/form\u003e \u003cform\u003e \u003cdiv class=\"form-group row\"\u003e \u003clabel for=\"inputDanceability\" class=\"col-sm-5 col-form-label\"\u003eDanceability: \u003c/label\u003e \u003cdiv class=\"col-sm-7\"\u003e \u003cselect id=\"inputDanceability\" class=\"custom-select\" ng-model=\"danceabilitySelect\" ng-options=\"x.level for x in criteriaOptions\"\u003e \u003coption value=\"\"\u003eSelect...\u003c/option\u003e \u003c/select\u003e \u003c/div\u003e \u003c/div\u003e \u003c/form\u003e \u003cform\u003e \u003cdiv class=\"form-group row\"\u003e \u003clabel for=\"inputEnergy\" class=\"col-sm-5 col-form-label\"\u003eEnergy: \u003c/label\u003e \u003cdiv class=\"col-sm-7\"\u003e \u003cselect id=\"inputEnergy\" class=\"custom-select\" ng-mode","date":"131313-09-00","objectID":"/posts/2018-04-13-angularjs-spotibar/:5:1","tags":null,"title":"[OLD] SpotiBar: ANGULARJS","uri":"/posts/2018-04-13-angularjs-spotibar/"},{"categories":["blog"],"content":"[This is a post from my old website. Outdated packages and libraries. Viewer discretion is advised ;-)] ","date":"131313-09-00","objectID":"/posts/2017-09-13-spotibar/:0:0","tags":null,"title":"[OLD] SpotiBar: Spotify + Foobar","uri":"/posts/2017-09-13-spotibar/"},{"categories":["blog"],"content":"SPOTIBAR Spotify zacząłem używać od momentu jak wprowadzili abonament w PLN. Kilka lat doświadczenia się zatem zebrało i choć bardzo sobie cenię tę usługę, to jest jedna rzecz, która mi strasznie w niej przeszkadza. {: .align-center} Od razu zaznaczę, że należę do grona ludzi, którzy trzymać swoją kolekcję muzyczną w ordnungu. Jak kupuję płytę CD, to znajduję dla niej miejsce na odpowiedniej półeczce, scrobbluję do last.fm z iTunesa, Spotify’a i telefonu, staram się pamiętać czy dany album mam na nośniku fizycznym, cyfrowym, w streamingu, i tak dalej. Zarządzanie kolekcją w Spotify kuleje. Jak tylko nasze playlisty przekroczą te kilkadziesiąt utworów, wzrokowe odnalezienie się w nich jest dla mnie niemożliwe. Jest searchbar po playliście, ale co z utworami, których nazwy nie potrafię przywołać a potrafię jedynie rozpoznać? Poza tym, jakbym chciał wszystko załatwiać klawiaturowo, to używałbym mpd + mopidy w terminalu. Listy mają za wysoką linię wiersza (nawet po zoom- na maksimum), nie mogę playlisty pokazać jako zbioru miniatur okładek/wykonawców, nie mogę szukać jednocześnie po wszystkich swoich playlistach/bibliotece (tylko po całej bazie utwórów), i tak dalej. Cała koncepcja biblioteki w Spotify leży i kwiczy. Gdybym miał przenieść tam bibliotekę wykonawców z last.fm, nie wiem w jaki sposób miałbym cokolwiek w niej znaleźć. Koniec końców moja przygoda ze Spotify wygląda tak, że nigdy wcześniej tak dużo nowej muzyki nie słuchałem, ale też nigdy wcześniej tak mało wykonawców/albumów nie zapamiętywałem. Przyjąłem więc rozwiązanie robocze: playlista jest albo pod gatunek albo pod dany temat. Przykładowo, wczesny black metal ma swoją playlistę, podobnie jak muzyka pasująca do pracy przy komputerze, czy jazdy samochodem. Mam też playlisty nieeleganckie: albumy do przesłuchania, utwory do uporządkowania i tym podobne. Być może taki urok czasów, presji wywoływanej samą możliwością słuchania czegokolwiek spośród X milionów dostępnych w Spotify utworów. Póki co nie potrafię tego rozstrzygnąć, ale pamiętam taki programik jak foobar2000. Był idealny dla moich potrzeb. Prosty, konfigurowalny do cna, w którym od razu wiedziałem, gdzie i w jakim miejscu kryje się ten utwór, na który mam w danym momencie ochotę. {: .align-center} Foobar2000 natywnie działa na Windowsie. Windowsa w domu nie posiadam od lat (Linux/MacOS). Uruchamianie na wrapperach, WINE’ach sprawia, że przestaję odczuwać radość z prostoty tego programu, poza tym pozostaje kwestia dostępu do bazy Spotify. Kończąc ten przydługawy wywód, powziąłem następujące wyzwanie: napiszę klienta webowego Spotify, który przynajmniej w małym wymiarze będzie mi przypominać korzystanie z foobara. Jeśli nie pomoże mi to odnaleźć się w kolekcji muzycznej, to będę już po wsze czasy wiedzieć, że albo zrezygnuję ze streamingu albo zmienię podejście do porządkowania muzyki. ","date":"131313-09-00","objectID":"/posts/2017-09-13-spotibar/:1:0","tags":null,"title":"[OLD] SpotiBar: Spotify + Foobar","uri":"/posts/2017-09-13-spotibar/"},{"categories":["blog"],"content":"Co Webowy klient Spotify Przynajmniej częściowa analogia interfejsu do podstawowego foobara ","date":"131313-09-00","objectID":"/posts/2017-09-13-spotibar/:1:1","tags":null,"title":"[OLD] SpotiBar: Spotify + Foobar","uri":"/posts/2017-09-13-spotibar/"},{"categories":["blog"],"content":"Czym Spotify Web API Spotify Web API Java - wrapper API dla Javy Spring MVC Póki nie będzie innych potrzeb: lokalny Tomcat albo MAMP (jeśli okaże się, że baza danych to jest to) Eclipse ","date":"131313-09-00","objectID":"/posts/2017-09-13-spotibar/:1:2","tags":null,"title":"[OLD] SpotiBar: Spotify + Foobar","uri":"/posts/2017-09-13-spotibar/"},{"categories":["blog"],"content":"PART 2 W poprzednim wpisie na ten temat obiecałem zrobić spotify’owy odpowiednik foobara. Choć idea była szczytna, to jednak minęła się trochę z momentem dziejowym. Gdybym obecne playlisty i bibliotekę Spotify miał na dysku twardym, to korzystając z Foobara bym się dawno… pochlastał. Problem leży raczej w moim podejściu do muzyki, aniżeli do interfejsu ;). Nadmiernie eklektyczny gust najwyraźniej też nie jest zbyt dobry. Ale to nie powód żeby całkiem rezygnować. Więc zrobiłem coś takiego: {: .align-center} Spotify w swoim API oferuje coś zwanego Recommendation Request. Zwraca on listę utworów spełniających rozmaite kryteria. Mamy tutaj (oprócz gatunku/artysty/utworu) współczynniki takie jak: taneczność, pozytywność, energiczność, tempo, tonacja, czas trwania, popularność i inne. Czyli możemy szukać czego podobnego do danego wykonawcy, co dodatkowo nie jest popularne Pola wyszukiwania są ustawione z walidacją, także w przypadku błędnego kryterium otrzymuje informację zwrotną, a nie błąd 400/502/itd. ;). Powinno to ustrzec przed wystąpieniem przynajmniej części wyjątków, których obsługą się nie zająłem… {: .align-center} Wyniki wypluwane są w bootstrapowej siatce (lekko zmodyfikowany motyw Superhero), z linkami do desktopowego klienta Spotify: {: .align-center} Wybrany na tym etapie pracy z API sposób autoryzacji z serwerami Spotify nie wymaga od użytkownika podawania jakichkolwiek danych (Client Credential flow bodajże), więc nie można zapisywać wyników automatycznie do playlist. Na boku chciałbym wyrazić ogromny smutek, że ludzie spoza zespołu Spotify nie mają już dostępu do API EchoNest. Every Noise at Once to doskonały przykład tego, co można z tych danych wyciągnąć… Póki co udostępniane przez Szwedów API jest bardziej okrojone :/. Kolejny smutek wywołało u mnie kryterium popularności. Niestety, Spotify nie sumuje różnych edycji tych samych utworów. Jeżeli jakiś utwór takiego Motorhead był wydany kilka razy na różnych składankach, reedycjach albumów, itd., to każdy z nich ma wszystkie współczynniki wyliczane osobno. Dlatego Ace of Spades potrafi nasza apka wypluć z zerową popularnością :D. A taka Madonna posiada utwory mniej popularne od niektórych Ulvera. Podsumowując, oto - działający po wrzuceniu na tomcata - sposób na bardziej zaawansowane wyszukiwanie w bazie Spotify. ","date":"131313-09-00","objectID":"/posts/2017-09-13-spotibar/:2:0","tags":null,"title":"[OLD] SpotiBar: Spotify + Foobar","uri":"/posts/2017-09-13-spotibar/"},{"categories":["blog"],"content":"Czym Spotify Web API wrapper dla Javy (forkowany przez dhughes) (wiem, że obecnie znowu rozbudowują główne repo, ale linkowana wersja działa mi wystarczająco dobrze :-)) Spring Framework 4 Hibernate Validator Tomcat 8 ","date":"131313-09-00","objectID":"/posts/2017-09-13-spotibar/:2:1","tags":null,"title":"[OLD] SpotiBar: Spotify + Foobar","uri":"/posts/2017-09-13-spotibar/"},{"categories":["blog"],"content":"Co tam jest Walidacja form, w tym własny walidator Builder pattern zbudowany nad builderem z wrappera (to było chyba bardzo głupie rozwiązanie, ale nie miałem pomysłu jak inaczej to zrobić, więcej o tym w przyszłości) Kilka .jsp, w nich zaś pętle i bootstrap ","date":"131313-09-00","objectID":"/posts/2017-09-13-spotibar/:2:2","tags":null,"title":"[OLD] SpotiBar: Spotify + Foobar","uri":"/posts/2017-09-13-spotibar/"},{"categories":["blog"],"content":"Kod źródłowy (trzeba zmodyfikować Stringi w SpotifyApiDAO.java na własne klucze developerskie Spotify) Jak zwykle na GitHub. {: .align-center} ","date":"131313-09-00","objectID":"/posts/2017-09-13-spotibar/:2:3","tags":null,"title":"[OLD] SpotiBar: Spotify + Foobar","uri":"/posts/2017-09-13-spotibar/"},{"categories":["blog"],"content":"PART 3 Po przerwie spowodowanej perturbacjami niezwiązanymi z programowaniem, zdecydowałem się spróbować innego języka. Ostatni mini-projekcik był fajny: wykorzystanie API, aplikacja internetowa, framework Javowy. Chcąc spróbować sił w czymś podobnym, wziąłem sobie na warsztat ten sam projekt, ale pisany w JS. Po dłuższych kłótniach z JS-owym stoiskiem Popularnych, Ważnych i Na Czasie frameworków, wybrałem AngularJS. Aplikacja działa, ale daleko jej do bycia ślicznotką. Bebechem CSSowym jest nadal Bootstrap, ale póki co i tak wygląda jak strona z lat 90. :-). Estetykę poprawimy w kolejnych wpisach, jak już zostaną opowiedziane koleje losu od zera (‘a gdzie w Javascripcie jest metoda main()?’) do bohatera zera i pół ;-). Tymczasem link do apki tutaj. ","date":"131313-09-00","objectID":"/posts/2017-09-13-spotibar/:3:0","tags":null,"title":"[OLD] SpotiBar: Spotify + Foobar","uri":"/posts/2017-09-13-spotibar/"},{"categories":["blog"],"content":"[This is a post from my old website. Outdated packages and libraries. Viewer discretion is advised ;-)] ","date":"6066-09-00","objectID":"/posts/2017-07-06-enumsql/:0:0","tags":null,"title":"[OLD] Java 101: Enum + Servlets","uri":"/posts/2017-07-06-enumsql/"},{"categories":["blog"],"content":"ENUM Typ enum, dodany w wersji 1.5, służy do definiowania stałych. Kiedy mamy z nim do czynienia, to wiemy że mamy do wyboru ograniczony zbiór możliwych opcji. Przykładowo, definiując enum poraRoku z góry wiemy, że będzie on przyjmować wartości jedynie spośród ZIMA, WIOSNA, LATO i JESIEN. Każdy enum domyślnie rozszerza klasę java.lang.Enum, dlatego nie może rozszerzać żadnej innej klasy. Może natomiast implementować interfejsy. Enumy możemy definiować również jako klasy wewnętrzne. Konstruktor może być protected (domyślnie) albo private. Nie przywołujemy go bezpośrednio. Weźmy nasz enum poraRoku: class EnumCwiczenie { enum poraRoku { ZIMA, WIOSNA, LATO, JESIEN } public static void main(String[] args) { System.out.println(poraRoku.LATO + \" to okres strasznej duchoty.\"); } } Efekt: LATO to okres strasznej duchoty. Ciało klasy (typu) enum może zawierać metody i inne pola. Domyślnie w trakcie kompilacji dodawana jest metoda values(), zwracająca tablicę wszystkich wartości naszego enum w kolejności ich deklaracji w kodzie. Zobaczmy jak możemy zawrzeć więcej informacji w stałych enum: class EnumCwiczenie { enum poraRoku { ZIMA(\"Gwiazdka\"), WIOSNA(\"Wielkanoc\"), LATO(\"Noc Kupaly\"), JESIEN(\"Zaduszki\"); private final String waznaData; poraRoku(String waznaData) { this.waznaData = waznaData; } String getWaznaData() { return waznaData; } } public static void main(String[] args) { System.out.println(poraRoku.LATO + \" to okres strasznej duchoty.\"); System.out.println(\"W trakcie tej pory roku ma miejsce \" + poraRoku.LATO.getWaznaData() + \".\"); for(poraRoku pora : poraRoku.values()) { System.out.println(\"W trakcie pory \" + pora + \" ma miejsce \" + pora.getWaznaData() + \".\"); } } } Efekt: LATO to okres strasznej duchoty. W trakcie tej pory roku ma miejsce Noc Kupaly. W trakcie pory ZIMA ma miejsce Gwiazdka. W trakcie pory WIOSNA ma miejsce Wielkanoc. W trakcie pory LATO ma miejsce Noc Kupaly. W trakcie pory JESIEN ma miejsce Zaduszki. Pełen zbiór domyślnych metod znaleźć można w dokumentacji. ","date":"6066-09-00","objectID":"/posts/2017-07-06-enumsql/:1:0","tags":null,"title":"[OLD] Java 101: Enum + Servlets","uri":"/posts/2017-07-06-enumsql/"},{"categories":["blog"],"content":"Kiedy stosować? Korzystając z enuma, mamy zagwarantowane istnienie tylko jednej instancji stałej (wygodny punkt wyjścia dla wzorca Singleton). Ponadto, możemy korzystać z operatora ==. Zawarta w klasie Enum metoda equals() działa dokładnie tak samo jak ten operator, ale jest metodą, więc możemy otrzymać wyjątek NullPointerException, zamiast wartości false jak w przypadku porównania enum przy pomocy == z null. Nie trzeba implementować interfejsu Serializable by móc serializować enumy. Ponadto, dokonując serializacji enuma, de facto serializowana jest jego nazwa, zwracana przez wbudowaną metodę name(), a przy deserializacji przywoływana jest metoda valueOf() naszego enuma, zwracająca stałą o tej nazwie. W ten sposób nie musimy serializować wartości wszytkich pól enuma. Enumy pozwalają także na wygodniejsze stosowanie wyrażeń switch: poraRoku jednaPoraRoku = poraRoku.WIOSNA; switch(jednaPoraRoku) { case LATO: System.out.println(\"Cieplo!\"); break; case ZIMA: System.out.println(\"Zimno!\"); break; case WIOSNA: System.out.println(\"W sam raz!\"); break; case JESIEN: System.out.println(\"Mokro!\"); break; } Efekt: W sam raz! Nie zawsze stosowanie typu enum jest korzystne. Zajmują one więcej miejsca w pamięci (powód dla którego ich stosowanie nie jest rekomendowane przez zespół Androida). Jeżeli nasze stałe nie mają żadnych dodatkowych pól, to prawdopodobnie mniej zasobów będzie zajmować zwyczajowe public static final. Z drugiej strony, enumy są łatwym sposobem obsługi stałych, które mają posiadać dodatkowe pola (a zatem więcej informacji) i własne metody. Czyli, jak zawsze, stosować w sposób przemyślany ;). ","date":"6066-09-00","objectID":"/posts/2017-07-06-enumsql/:1:1","tags":null,"title":"[OLD] Java 101: Enum + Servlets","uri":"/posts/2017-07-06-enumsql/"},{"categories":["blog"],"content":"Prosta aplikacja webowa: Servlets, Tomcat Mówiąc w skrócie, servlety to klasy pomagające serwerowi w odpowiadaniu na żądania ze strony klienta. Jako że najczęściej żądania są w protokole HTTP, to pisząc servlet zwykle rozszerzamy klasę javax.servlet.http.HttpServlet, i nie bawimy się w implementację samego interfejsu javax.servlet.Servlet. Zwróćcie uwagę na początek tych nazw: javax, nie zwykłe java. Standardowa edycja Javy nie zawiera servletów, Jeżeli używaliście wcześniej platformy Javy SE, to będziecie musieli ściągnąć brakujące biblioteki, albo po prostu przerzucić się na Javę EE, która je (i inne) zawiera. Przykładowo, jeśli korzystacie z Eclipse’a, macie do wyboru kilka wersji programu. Zainstalujcie wersję dla Javy EE i będziecie mieć spokój ;). Potrzebny jest też serwer oraz (akurat dla potrzeb takich servletów, jakie napiszemy) baza danych. W poniższych przykładach wykorzystany jest Tomcat oraz MySQL. Nie będziemy krok po kroku przerabiać ich instalacji, w internecie bez problemu można znaleźć instrukcje do każdego systemu operacyjnego. Za pierwszym razem może to trochę czasu zająć, szczególnie jeśli się nie miało wcześniej do czynienia z linią komend, ale warto tę chwilę poświęcić. Założenie jest zatem takie, że Tomcat jest zainstalowany, a na dysku utworzona została baza danych MySQL. javax.servlet.http.HttpServlet zawiera szereg metod odpowiadającym żądaniom HTTP. Skorzystamy z metod doGet() oraz doPost(). Różnica pomiędzy GET a POST polega na widoczności przesyłanych danych. Żądanie GET zawiera przesyłane do serwera informacje w adresie URL (można więc podejrzeć je nawet w historii przeglądarki), stąd dane muszą być zapisane za pomocą znaków ASCII. Przeglądarki i serwery nakładają ograniczenia na maksymalną długość adresu URL (od 2048 w górę), więc i z tej perspektywy jesteśmy ograniczeni. Dla żądania POST format danych nie jest tak istotny. Napiszemy bardzo prostą aplikację webową: pamiętnik operujący na lokalnym serwerze. ","date":"6066-09-00","objectID":"/posts/2017-07-06-enumsql/:2:0","tags":null,"title":"[OLD] Java 101: Enum + Servlets","uri":"/posts/2017-07-06-enumsql/"},{"categories":["blog"],"content":"Przygotowania* (*Eclipse, wszystko można zrobić bez pomocy IDE) Potrzebny jest nam nowy projekt, skonfigurowany do działania na serwerze. W Eclipse klikamy **File **-\u003e **New **-\u003e Dynamic Web Project. Po podaniu nazwy projektu, obok pola Target runtime klikamy przycisk New Runtime…, wybieramy wersję Tomcata, klikamy Finish. Kreator projektu również zamykamy klikając Finish. Ok, mamy lokalny serwer, na którym będziemy odpalać nasze servlety. Teraz baza danych. Upewnij się, że masz włączony domyślną perspektywę w Eclipse (_Window _-\u003e Perspective -\u003e Open perspective -\u003e Java EE). U dołu okna IDE kliknij w Data Source Explorer i prawym przycikiem myszy na Database Connections. Kliknij New, z listy wybierz MySQL. Po naciśnięciu Next wpisz dane do swojej bazy danych (nazwa pod polem Database, pełen URL, login i hasło). Jeżeli po naciśnięciu Test Connection pokazuje się komunikat o niepowodzeniu, sprawdź wybrany sterownik. W naszym wypadku jest to JDBC Driver, ściągnąć go można tutaj. a zmienić naciskając na ikonę trójkąta po prawej strony od listy sterowników, wskazując na miejsce, gdzie tenże .jar znajduje się na dysku. {: .align-center} W naszym wypadku baza danych nazywa się diary, a przygotowana wcześniej tabela ENTRIES, z następującymi kolumnami: CREATE TABLE ENTRIES( id INT NOT NULL AUTO_INCREMENT, title VARCHAR(200), date DATETIME, content LONGTEXT, PRIMARY KEY ( id ) ); ","date":"6066-09-00","objectID":"/posts/2017-07-06-enumsql/:2:1","tags":null,"title":"[OLD] Java 101: Enum + Servlets","uri":"/posts/2017-07-06-enumsql/"},{"categories":["blog"],"content":"Servlet pobierający informacje z bazy danych Tak jak wyżej napisano, servlety służące do obsługi żądań HTTP powinny rozszerzać klasę javax.servlet.http.HttpServlet. A więc: @WebServlet(\"/DiaryArchive\") public class DiaryArchive extends HttpServlet { } Kilka słów o @WebServlet. Pojawiła się ona w specyfikacji Servlet 3.0. Wcześniej dla każdej aplikacji sieciowej obsługiwanej przy pomocy servletów należało tworzyć deskryptor w pliku web.xml, w którym m.in. umieszczaliśmy informacje na temat wszystkich servletów. Dzięki temu kontener servletów (w naszym przypadku Tomcat) wiedział, który servlet powinien odpalić na dany typ żądania ze strony klienta. Adnotacja @WebServlet ułatwia nam pracę, takowego pliku przygotowywać nie trzeba (Tomcat ją obsługuje od wersji 7.0). W dokumentacji wymieniony jest szereg atrybutów adnotacji, ale podawać trzeba jedynie urlPatterns/value, wskazując URL pod którym nasz servlet będzie aktywny. Nasz pierwszy servlet będzie służyć do odczytywania z bazy danych wpisów z pamiętnika. Żadnych specjalnych danych do serwera nie przesyłamy, tylko żądanie wyświetlenia wpisów, więc skorzystamy z żądania GET, a więc przesłaniamy metodę doGet(). Od razu ustalimy typ odpowiedzi (będzie to wyświetlany w przeglądarce html) oraz przygotujemy przypiszemy zmienną out do obiektu PrintWriter wziętego z HttpServletResponse. Ten posłuży nam do przesłania tekstu (kodu html) do klienta: protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType(\"text/html\"); PrintWriter out = response.getWriter(); } Czas na małe parsowanie. Najpierw część kodu html, do którego nie potrzebujemy informacji z bazy danych: String title = \"My Db Diary\"; String docType = \"\u003c!DOCTYPE html\u003e\\n\"; out.println(docType + \"\u003chtml\u003e\\n\" + \"\u003chead\u003e\u003ctitle\u003e\" + title + \"\u003c/title\u003e\u003c/header\u003e\\n\" + \"\u003cbody bgcolor = \\\"#f3f3f3\\\"\u003e\\n\" + \"\u003ch1 align = \\\"center\\\"\u003e\" + title + \"\u003c/h1\u003e\\n\" + \"\u003ch3 align = \\\"center\\\"\u003e\u003ca href=\\\"http://localhost:8080/DiaryServlet/DiaryMain.html\\\"\u003eAdd new entry\u003c/a\u003e\u003c/h3\u003e\"); Od razu zawarliśmy w nim URL, pod którym będzie działać nasz drugi servlet. Na razie wejście pod ten adres wywołałoby jedynie błędy. Pozostaje nam połączenie się z bazą danych, pobranie wpisów i sparsowanie ich do kodu HTML. Najpierw kilka stałych: private static final String JDBC_DRIVER = \"com.mysql.jdbc.Driver\"; private static final String DB_URL = \"jdbc:mysql://localhost:3306/diary\"; // Adres naszej bazy MySQL private static final String USER = \"root\"; // Login do bazy private static final String PASS = \"root\"; // Hasło do bazy try { // Rejestrujemy sterownik. Class.forName(JDBC_DRIVER); // Podłączamy się do naszej bazy MySQL Connection con = DriverManager.getConnection(DB_URL, USER, PASS); // Przygotowujemy zapytanie do bazy oraz obiekt klasy ResultSet z danymi zwrotnymi. Statement stmt = con.createStatement(); String sql = \"SELECT id, date, title, content FROM ENTRIES\"; ResultSet rs = stmt.executeQuery(sql); // Parsujemy każdy kolejny wiersz pobrany do obiektu ResultSet do kodu HTML. while(rs.next()) { int id = rs.getInt(\"id\"); Timestamp ts = rs.getTimestamp(\"date\"); String entryTitle = rs.getString(\"title\"); String entryContent = rs.getString(\"content\"); out.println(\"\u003ch3 align = \\\"center\\\"\u003e\" + id + \": \" + ts.toString() + \"\u003c/h3\u003e\"); out.println(\"\u003ch2 align = \\\"center\\\"\u003e\" + entryTitle + \"\u003c/h2\u003e\u003cbr\u003e\"); out.println(entryContent + \"\u003cbr\u003e\"); } out.println(\"\u003c/body\u003e\u003c/html\u003e\"); // Zamykamy połączenia z bazą danych (dla przejrzystości przykładu zakładamy, że nie wystąpią w tym miejscu wyjątki). rs.close(); stmt.close(); con.close(); } catch(SQLException se) { se.printStackTrace(); } catch(Exception e) { e.printStackTrace(); } Pierwszy servlet gotowy. Gdy klikniemy Run -\u003e Run as… -\u003e Run on Server powinniśmy ujrzeć coś takiego: {: .align-center} Zwróćcie uwagę, że adres URL to połączony adres bazy danych oraz adresu podanego w adnotacji @WebServlet. Czas na drugi servlet, pozwalający na dodawanie nowych wpisów do baz","date":"6066-09-00","objectID":"/posts/2017-07-06-enumsql/:2:2","tags":null,"title":"[OLD] Java 101: Enum + Servlets","uri":"/posts/2017-07-06-enumsql/"},{"categories":["blog"],"content":"[This is a post from my old website. Outdated packages and libraries. Viewer discretion is advised ;-)] ","date":"171717-09-00","objectID":"/posts/2017-05-17-android_courier_firebase/:0:0","tags":null,"title":"[OLD] Courier App for Android","uri":"/posts/2017-05-17-android_courier_firebase/"},{"categories":["blog"],"content":"FIRST PART The idea for a courier app isn’t new. You can find countless examples on Google Play Store. But building one is actually quite handy exercise in integrating Android with Firebase services. In this series we will cover only parts of building the actual bike courier app. Focus will be on Firebase integration and also some design pattern strategies. Android code can look really ugly really quick if you just put everything within your Activity class. ","date":"171717-09-00","objectID":"/posts/2017-05-17-android_courier_firebase/:1:0","tags":null,"title":"[OLD] Courier App for Android","uri":"/posts/2017-05-17-android_courier_firebase/"},{"categories":["blog"],"content":"App requirements – what should it allow Register new users and log in already existing users. Place orders. Inform couriers that a new order is pending. Provide couriers with details on accepted order. Update customers on their order’s status with notifications. Access to order history. Some basic account informations and ability to edit those (i.e. change password or company name). Contact information for the company. ","date":"171717-09-00","objectID":"/posts/2017-05-17-android_courier_firebase/:1:1","tags":null,"title":"[OLD] Courier App for Android","uri":"/posts/2017-05-17-android_courier_firebase/"},{"categories":["blog"],"content":"What will we use? APIs \u0026 software We will use pretty much only Google APIs and services: Places, Maps, Firebase Authentication, Firebase Realtime Database and Firebase Cloud Functions. We will code in Android Studio (2.3.2 at the moment of writing this post). ","date":"171717-09-00","objectID":"/posts/2017-05-17-android_courier_firebase/:1:2","tags":null,"title":"[OLD] Courier App for Android","uri":"/posts/2017-05-17-android_courier_firebase/"},{"categories":["blog"],"content":"How will it look in the end? – Source code All of the code discussed in this series can be found on my Github. ","date":"171717-09-00","objectID":"/posts/2017-05-17-android_courier_firebase/:1:3","tags":null,"title":"[OLD] Courier App for Android","uri":"/posts/2017-05-17-android_courier_firebase/"},{"categories":["blog"],"content":"Sidenote ! The code’s quality isn’t the best imaginable. I’m just a beginner as well, so there is a lot of room for optimisation. That being said, if you feel a little bit lost in dealing with official Android/Firebase documentation, or do not know what Firebase is, this series should be able to help you. ","date":"171717-09-00","objectID":"/posts/2017-05-17-android_courier_firebase/:1:4","tags":null,"title":"[OLD] Courier App for Android","uri":"/posts/2017-05-17-android_courier_firebase/"},{"categories":["blog"],"content":"PART 2: Firebase ","date":"171717-09-00","objectID":"/posts/2017-05-17-android_courier_firebase/:2:0","tags":null,"title":"[OLD] Courier App for Android","uri":"/posts/2017-05-17-android_courier_firebase/"},{"categories":["blog"],"content":"What is Firebase Firebase is a Google platform, a replacement to a traditional server-side solutions. With it, you don’t have to own a server and you don’t need to spend time configuring one from the scratch. If your needs are small enough, you don’t even have to pay for it. Most apps nowadays need some sort of back-end. It wouldn’t be wise to keep all of the users information only on his/hers phone or computer. How would you recover user email if needed? Actually, how else could you enable accounts at all in your app? Send notifications? A need for one central place to store data is pretty common. Firebase itself is more than just a database service. It can manage your users authentication process, database needs, notifications, custom node.js scripts, store user files, allows you to manage AdMob in your app, analyse user traffic and app usage, it pretty much functions like a ready-to-go server and cloud. Imagine you have a mobile app and a web app. To connect the two all you have to do is to pin both apps to the same Firebase project. The best part is you don’t even need to know any SQL, PHP or other popular server-side languages. Firebase interface is ‘clickable’, so on the most part you will only have to write client-side code. At some point it will probably be better to learn some code, though. Especially if you would like to automate some processes like responding to some database events (NoSQL and node.js). ","date":"171717-09-00","objectID":"/posts/2017-05-17-android_courier_firebase/:2:1","tags":null,"title":"[OLD] Courier App for Android","uri":"/posts/2017-05-17-android_courier_firebase/"},{"categories":["blog"],"content":"Ok, so how do I connect my app to it? Easy-peasy. Go to firebase.google.com and create an account. Then head over to Firebase Console and create a new project (you can attach multiple mobile/web apps to one project). Click Add Project: {: .align-center} When you created the project, click on Android icon to add your Android Studio app to your Firebase project: {: .align-center} A window will pop up asking you for some information. At the Android package name enter the complete name of your app. {: .align-center} For the third field you can provide your debug SHA-1 fingerprint (it allows you to use some of the Google Play Services like Google Sign-In). Getting that value can be easily achieved with command-line. For Linux/MacOs machines: keytool -exportcert -list -v \\ -alias androiddebugkey -keystore ~/.android/debug.keystore For Windows: keytool -exportcert -list -v \\ -alias androiddebugkey -keystore %USERPROFILE%\\.android\\debug.keystore If you don’t feel comfortable with command line, you can also click your way through to this value. Click following things in Android Studio and copy-paste SHA-1: {: .align-center} When you filled fields click Register App. A .json file will be downloaded. You need to put this file into your project in the following place (you can do that by dragging it to the relevant place in Android Studio or simply by navigating to your project folder on the hard-drive and pasting at the right place): {: .align-center} Remember to make sure that only you have access to google-services.json file, as it contains all necessary information for your app to connect to the Firebase. If you are publishing your code on your Github or somewhere else, do not upload this file. Lastly, you need to take care of dependencies. You have to edit two .gradle build files: {: .align-center} In your project-level build.gradle add following line of code: buildscript { dependencies { classpath 'com.google.gms:google-services:3.0.0' } } In your app-level build.gradle add following line of code **at the bottom **of the file: apply plugin: 'com.google.gms.google-services' When you edit either of the build.gradle files a information bar will appear in Android Studio telling you to sync your project. When you’ve finished editing these files click on Sync now button: {: .align-center} There you go! You connected your app to Firebase project. ","date":"171717-09-00","objectID":"/posts/2017-05-17-android_courier_firebase/:2:2","tags":null,"title":"[OLD] Courier App for Android","uri":"/posts/2017-05-17-android_courier_firebase/"},{"categories":["blog"],"content":"Easier way Described method is manual and can seem complicated at the beginning, but I strongly recommend you to at least use it once. Otherwise how will you know exactly which files need to be altered for you to be connected with Firebase? That being said there is also an easier way to connect your app. In Android Studio click on Tools \u003e **Firebase **and then expand one of the features in the newly opened **Assistant **window. Upon expanding click the Connect to Firebase button and follow instructions on the screen. ","date":"171717-09-00","objectID":"/posts/2017-05-17-android_courier_firebase/:2:3","tags":null,"title":"[OLD] Courier App for Android","uri":"/posts/2017-05-17-android_courier_firebase/"},{"categories":["blog"],"content":"PART 3 ","date":"171717-09-00","objectID":"/posts/2017-05-17-android_courier_firebase/:3:0","tags":null,"title":"[OLD] Courier App for Android","uri":"/posts/2017-05-17-android_courier_firebase/"},{"categories":["blog"],"content":"Do we need to create user accounts We want users of our app to be able to order bike courier services. Our customers will most likely be companies trying to transport documents from one place to the other. Not that a lot of individuals use this sort of service. It would be cumbersome for customers to provide all of the relevant data each time they place a new order, like their telephone number or e-mail address. So we should store that data once and reuse it. One way of doing this is to store data permanently in the user phone. However, information would be lost upon deleting app from the device. Heck, what if user switched his phone to a newer one? We need a solution independent from the user. We need back-end. ","date":"171717-09-00","objectID":"/posts/2017-05-17-android_courier_firebase/:3:1","tags":null,"title":"[OLD] Courier App for Android","uri":"/posts/2017-05-17-android_courier_firebase/"},{"categories":["blog"],"content":"What will we use? Needs and requirements We will integrate Firebase Authentication and Firebase Realtime Database to our app. Create two activities: RegisterActivity and LoginActivity. Since user shouldn’t see signup screen each time he/she opens the app, let’s set AndroidManifest.xml file accordingly: \u003cactivity android:name=\".RegisterActivity\"\u003e \u003c/activity\u003e \u003cactivity android:name=\".LoginActivity\"\u003e \u003cintent-filter\u003e \u003caction android:name=\"android.intent.action.MAIN\"/\u003e \u003ccategory android:name=\"android.intent.category.LAUNCHER\"/\u003e \u003c/intent-filter\u003e \u003c/activity\u003e This way LoginActivity will be loaded directly after launching the app. We don’t cover the details of Activity creation here. Just make sure to provide user with EditViews and Buttons (or alternatives), so that there is a way for them to enter the information needed for signing up and signing in. The Activities can look something like this: {: .align-center} {: .align-center} As you can see in RegisterActivity we have four EditText objects: one for e-mail, one for password, one for phone number and one for company name. First of all we should check whether user is already signed in (what’s the point of signing up then?). To do that we need two class variables: private FirebaseAuth mAuth; private FirebaseAuth.AuthStateListener mAuthStateListener; (...) @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_register); mAuth = FirebaseAuth.getInstance(); // Create an instance of AuthStateListener, which checks whether user is signed in mAuthStateListener = new FirebaseAuth.AuthStateListener() { @Override public void onAuthStateChanged(@NonNull FirebaseAuth firebaseAuth) { FirebaseUser user = firebaseAuth.getCurrentUser(); if(user != null) { // User is signed in. Go to MainActivity (we will discuss it in later posts) startActivity(new Intent(getApplicationContext(), MainActivity.class)); } else { // User is signed out. } } } } (…) // Add AuthStateListener to our main FirebaseAuth object at onStart and remove it at onStop(). @Override public void onStart() { super.onStart(); mAuth.addAuthStateListener(mAuthStateListener); } @Override public void onStop() { super.onStop(); mAuth.removeAuthStateListener(mAuthStateListener); } If you’re unfamiliar with onStart() and onStop() method, check this article on Android activities lifecycle’. Basically, if user is already signed in, the MainActivity will be loaded. We will discuss that activity in later posts. For now all we want is to prohibit users from creating an account when they’re already have one. Ok, now to the actual signing up process. We have SignupButton view. Once it is clicked, assuming that every EditText field is filled, it’s going to perform the actual signing process in Firebase. What’s important to remember is that Firebase Authentication is a separate process from saving user’s data to Firebase Database. First one requires FirebaseAuth.createUserWithEmailAndPassword(String email, String password) call, and the second requires reference to the database. Let’s add that Button listener in our onCreate() method: private ProgressDialog mProgressDialog; @Override protected void onCreate(Bundle savedInstanceState) { (...) mSignUpButton.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View v) { registerUser(); } }); } (…) private void registerUser() { // Get Strings from EditTexts final String mEmail = mEditTextEmail.getText().toString().trim(); final String mPhone = mEditTextPhone.getText().toString().trim(); final String mName = mEditTextName.getText().toString().trim(); String mPass = mEditTextPassword.getText().toString().trim(); // Preliminary check for whether EditTexts weren't empty. If empty, show Toast to the user with information. if(TextUtils.isEmpty(mEmail)){ Toast.makeText(this,getString(R.string.login_hint_email), Toast.LENGTH_LONG).show(); return; } if(TextUtils.isEmpty(mPass)){ Toast.makeText(this,getString(R.str","date":"171717-09-00","objectID":"/posts/2017-05-17-android_courier_firebase/:3:2","tags":null,"title":"[OLD] Courier App for Android","uri":"/posts/2017-05-17-android_courier_firebase/"}]